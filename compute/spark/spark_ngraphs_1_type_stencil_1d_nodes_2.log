2019-03-03 17:08:11 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 17:08:12 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 17:08:12 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 17:08:12 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 17:08:12 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 17:08:12 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 17:08:12 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 17:08:12 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 17:08:13 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40238.
2019-03-03 17:08:13 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 17:08:13 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 17:08:13 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 17:08:13 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 17:08:13 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-7c62dc45-90e3-4b99-9420-9b9f3bc14788
2019-03-03 17:08:13 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 17:08:13 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 17:08:13 INFO  log:192 - Logging initialized @5397ms
2019-03-03 17:08:13 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 17:08:13 INFO  Server:414 - Started @5505ms
2019-03-03 17:08:13 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 17:08:13 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 17:08:13 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00797:4040
2019-03-03 17:08:13 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00797:40238/jars/Taskbench-assembly-1.0.jar with timestamp 1551661693669
2019-03-03 17:08:13 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00797:40238/files/libcore_c.so with timestamp 1551661693672
2019-03-03 17:08:13 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-2b77b900-e7ec-46eb-ab30-ccbbe47a7a28/userFiles-0e86ef03-f8f3-40ca-8784-1f705fc687f5/libcore_c.so
2019-03-03 17:08:13 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00797:7077...
2019-03-03 17:08:13 INFO  TransportClientFactory:267 - Successfully created connection to nid00797/10.128.3.36:7077 after 48 ms (0 ms spent in bootstraps)
2019-03-03 17:08:14 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303170814-0000
2019-03-03 17:08:14 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40401.
2019-03-03 17:08:14 INFO  NettyBlockTransferService:54 - Server created on nid00797:40401
2019-03-03 17:08:14 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 17:08:14 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00797, 40401, None)
2019-03-03 17:08:14 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00797:40401 with 34.0 GB RAM, BlockManagerId(driver, nid00797, 40401, None)
2019-03-03 17:08:14 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00797, 40401, None)
2019-03-03 17:08:14 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00797, 40401, None)
2019-03-03 17:08:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 17:08:14 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 60
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 64
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 268435456
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 64000
Total Dependencies 190000
Total FLOPs 2199023259648000
Total Bytes 0
Elapsed Time 1.931129e+03 seconds
FLOP/s 1.138724e+12
B/s 0.000000e+00
2019-03-03 18:15:29 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 18:15:32 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 18:15:32 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 18:15:32 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 18:15:32 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 18:15:32 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 18:15:32 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 18:15:32 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 18:15:33 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 39520.
2019-03-03 18:15:33 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 18:15:33 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 18:15:33 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 18:15:33 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 18:15:33 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-e23cc8a4-a85b-4813-96b6-7a2597aa31d6
2019-03-03 18:15:33 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 18:15:33 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 18:15:33 INFO  log:192 - Logging initialized @7010ms
2019-03-03 18:15:33 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 18:15:33 INFO  Server:414 - Started @7104ms
2019-03-03 18:15:33 INFO  AbstractConnector:278 - Started ServerConnector@779dfe55{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 18:15:33 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 18:15:33 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00797:4040
2019-03-03 18:15:33 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00797:39520/jars/Taskbench-assembly-1.0.jar with timestamp 1551665733700
2019-03-03 18:15:33 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00797:39520/files/libcore_c.so with timestamp 1551665733703
2019-03-03 18:15:33 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-93fac4a3-71c2-43b0-9788-c5dd2d63a239/userFiles-2ca9a82c-9879-4332-b852-5a9bc6903231/libcore_c.so
2019-03-03 18:15:33 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00797:7077...
2019-03-03 18:15:33 INFO  TransportClientFactory:267 - Successfully created connection to nid00797/10.128.3.36:7077 after 52 ms (0 ms spent in bootstraps)
2019-03-03 18:15:34 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303181534-0001
2019-03-03 18:15:34 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303181534-0001/0 on worker-20190303170816-10.128.4.236-34604 (10.128.4.236:34604) with 16 core(s)
2019-03-03 18:15:34 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303181534-0001/0 on hostPort 10.128.4.236:34604 with 16 core(s), 64.0 GB RAM
2019-03-03 18:15:34 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303181534-0001/1 on worker-20190303170815-10.128.4.237-43385 (10.128.4.237:43385) with 16 core(s)
2019-03-03 18:15:34 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303181534-0001/1 on hostPort 10.128.4.237:43385 with 16 core(s), 64.0 GB RAM
2019-03-03 18:15:34 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303181534-0001/2 on worker-20190303170816-10.128.4.236-36408 (10.128.4.236:36408) with 16 core(s)
2019-03-03 18:15:34 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303181534-0001/2 on hostPort 10.128.4.236:36408 with 16 core(s), 64.0 GB RAM
2019-03-03 18:15:34 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303181534-0001/3 on worker-20190303170815-10.128.4.237-34711 (10.128.4.237:34711) with 16 core(s)
2019-03-03 18:15:34 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303181534-0001/3 on hostPort 10.128.4.237:34711 with 16 core(s), 64.0 GB RAM
2019-03-03 18:15:34 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35433.
2019-03-03 18:15:34 INFO  NettyBlockTransferService:54 - Server created on nid00797:35433
2019-03-03 18:15:34 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 18:15:34 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00797, 35433, None)
2019-03-03 18:15:34 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00797:35433 with 34.0 GB RAM, BlockManagerId(driver, nid00797, 35433, None)
2019-03-03 18:15:34 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00797, 35433, None)
2019-03-03 18:15:34 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00797, 35433, None)
2019-03-03 18:15:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 18:15:34 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 60
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 64
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 134217728
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 64000
Total Dependencies 190000
Total FLOPs 1099511631872000
Total Bytes 0
Elapsed Time 8.556703e+02 seconds
FLOP/s 1.284971e+12
B/s 0.000000e+00
2019-03-03 18:44:44 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 18:44:45 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 18:44:45 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 18:44:45 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 18:44:45 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 18:44:45 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 18:44:45 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 18:44:45 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 18:44:46 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 38242.
2019-03-03 18:44:46 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 18:44:46 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 18:44:46 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 18:44:46 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 18:44:46 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-1b645cd0-d7fd-45fb-a916-cb0e95582829
2019-03-03 18:44:46 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 18:44:46 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 18:44:46 INFO  log:192 - Logging initialized @8617ms
2019-03-03 18:44:46 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 18:44:46 INFO  Server:414 - Started @8715ms
2019-03-03 18:44:46 INFO  AbstractConnector:278 - Started ServerConnector@3623abdd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 18:44:46 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 18:44:46 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00797:4040
2019-03-03 18:44:46 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00797:38242/jars/Taskbench-assembly-1.0.jar with timestamp 1551667486598
2019-03-03 18:44:46 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00797:38242/files/libcore_c.so with timestamp 1551667486601
2019-03-03 18:44:46 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-5a3a838b-bc82-4d6a-aad8-b943e0ba2357/userFiles-6f123eac-50a2-4357-ab72-2ba08726bd3e/libcore_c.so
2019-03-03 18:44:46 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00797:7077...
2019-03-03 18:44:46 INFO  TransportClientFactory:267 - Successfully created connection to nid00797/10.128.3.36:7077 after 48 ms (0 ms spent in bootstraps)
2019-03-03 18:44:46 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303184446-0002
2019-03-03 18:44:46 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303184446-0002/0 on worker-20190303170816-10.128.4.236-34604 (10.128.4.236:34604) with 16 core(s)
2019-03-03 18:44:46 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303184446-0002/0 on hostPort 10.128.4.236:34604 with 16 core(s), 64.0 GB RAM
2019-03-03 18:44:46 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303184446-0002/1 on worker-20190303170815-10.128.4.237-43385 (10.128.4.237:43385) with 16 core(s)
2019-03-03 18:44:46 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303184446-0002/1 on hostPort 10.128.4.237:43385 with 16 core(s), 64.0 GB RAM
2019-03-03 18:44:46 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303184446-0002/2 on worker-20190303170816-10.128.4.236-36408 (10.128.4.236:36408) with 16 core(s)
2019-03-03 18:44:46 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303184446-0002/2 on hostPort 10.128.4.236:36408 with 16 core(s), 64.0 GB RAM
2019-03-03 18:44:46 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303184446-0002/3 on worker-20190303170815-10.128.4.237-34711 (10.128.4.237:34711) with 16 core(s)
2019-03-03 18:44:46 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303184446-0002/3 on hostPort 10.128.4.237:34711 with 16 core(s), 64.0 GB RAM
2019-03-03 18:44:46 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44323.
2019-03-03 18:44:46 INFO  NettyBlockTransferService:54 - Server created on nid00797:44323
2019-03-03 18:44:46 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 18:44:46 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00797, 44323, None)
2019-03-03 18:44:46 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00797:44323 with 34.0 GB RAM, BlockManagerId(driver, nid00797, 44323, None)
2019-03-03 18:44:46 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00797, 44323, None)
2019-03-03 18:44:46 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00797, 44323, None)
2019-03-03 18:44:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 18:44:47 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 60
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 64
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 134217728
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 64000
Total Dependencies 190000
Total FLOPs 1099511631872000
Total Bytes 0
Elapsed Time 1.029274e+03 seconds
FLOP/s 1.068240e+12
B/s 0.000000e+00
2019-03-03 19:19:31 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:19:31 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:19:31 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:19:31 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:19:31 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:19:31 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:19:31 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:19:31 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:19:32 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35834.
2019-03-03 19:19:32 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:19:32 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:19:32 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:19:32 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:19:32 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-7776c733-5e6c-47c2-ac09-2f93d2e40a67
2019-03-03 19:19:32 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:19:32 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:19:32 INFO  log:192 - Logging initialized @4346ms
2019-03-03 19:19:32 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:19:32 INFO  Server:414 - Started @4445ms
2019-03-03 19:19:32 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:19:32 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:19:32 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00797:4040
2019-03-03 19:19:32 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00797:35834/jars/Taskbench-assembly-1.0.jar with timestamp 1551669572720
2019-03-03 19:19:32 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00797:35834/files/libcore_c.so with timestamp 1551669572723
2019-03-03 19:19:32 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-8a70df10-3795-4c42-a0ca-6fc7020503a0/userFiles-27f406ab-3550-4ea5-ac09-5f4bbf972cc5/libcore_c.so
2019-03-03 19:19:32 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00797:7077...
2019-03-03 19:19:32 INFO  TransportClientFactory:267 - Successfully created connection to nid00797/10.128.3.36:7077 after 44 ms (0 ms spent in bootstraps)
2019-03-03 19:19:33 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303191933-0003
2019-03-03 19:19:33 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303191933-0003/0 on worker-20190303170816-10.128.4.236-34604 (10.128.4.236:34604) with 16 core(s)
2019-03-03 19:19:33 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303191933-0003/0 on hostPort 10.128.4.236:34604 with 16 core(s), 64.0 GB RAM
2019-03-03 19:19:33 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303191933-0003/1 on worker-20190303170815-10.128.4.237-43385 (10.128.4.237:43385) with 16 core(s)
2019-03-03 19:19:33 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303191933-0003/1 on hostPort 10.128.4.237:43385 with 16 core(s), 64.0 GB RAM
2019-03-03 19:19:33 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303191933-0003/2 on worker-20190303170816-10.128.4.236-36408 (10.128.4.236:36408) with 16 core(s)
2019-03-03 19:19:33 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303191933-0003/2 on hostPort 10.128.4.236:36408 with 16 core(s), 64.0 GB RAM
2019-03-03 19:19:33 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303191933-0003/3 on worker-20190303170815-10.128.4.237-34711 (10.128.4.237:34711) with 16 core(s)
2019-03-03 19:19:33 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303191933-0003/3 on hostPort 10.128.4.237:34711 with 16 core(s), 64.0 GB RAM
2019-03-03 19:19:33 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41094.
2019-03-03 19:19:33 INFO  NettyBlockTransferService:54 - Server created on nid00797:41094
2019-03-03 19:19:33 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:19:33 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00797, 41094, None)
2019-03-03 19:19:33 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00797:41094 with 34.0 GB RAM, BlockManagerId(driver, nid00797, 41094, None)
2019-03-03 19:19:33 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00797, 41094, None)
2019-03-03 19:19:33 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00797, 41094, None)
2019-03-03 19:19:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:19:33 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 60
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 64
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 67108864
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 64000
Total Dependencies 190000
Total FLOPs 549755817984000
Total Bytes 0
Elapsed Time 5.604965e+02 seconds
FLOP/s 9.808372e+11
B/s 0.000000e+00
2019-03-03 19:38:43 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:38:43 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:38:43 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:38:43 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:38:43 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:38:43 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:38:43 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:38:43 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:38:44 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 39970.
2019-03-03 19:38:44 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:38:44 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:38:44 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:38:44 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:38:44 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-bfd02b97-59ea-44ee-be41-2636796a350f
2019-03-03 19:38:44 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:38:44 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:38:44 INFO  log:192 - Logging initialized @4914ms
2019-03-03 19:38:44 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:38:44 INFO  Server:414 - Started @5016ms
2019-03-03 19:38:44 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:38:44 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:38:44 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00797:4040
2019-03-03 19:38:44 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00797:39970/jars/Taskbench-assembly-1.0.jar with timestamp 1551670724640
2019-03-03 19:38:44 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00797:39970/files/libcore_c.so with timestamp 1551670724643
2019-03-03 19:38:44 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-906e5282-aad1-490b-99af-1dea5cfa86ce/userFiles-f0124d6c-3dbd-49f0-85cc-f0045050d038/libcore_c.so
2019-03-03 19:38:44 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00797:7077...
2019-03-03 19:38:44 INFO  TransportClientFactory:267 - Successfully created connection to nid00797/10.128.3.36:7077 after 47 ms (0 ms spent in bootstraps)
2019-03-03 19:38:44 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303193844-0004
2019-03-03 19:38:44 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303193844-0004/0 on worker-20190303170816-10.128.4.236-34604 (10.128.4.236:34604) with 16 core(s)
2019-03-03 19:38:44 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303193844-0004/0 on hostPort 10.128.4.236:34604 with 16 core(s), 64.0 GB RAM
2019-03-03 19:38:44 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303193844-0004/1 on worker-20190303170815-10.128.4.237-43385 (10.128.4.237:43385) with 16 core(s)
2019-03-03 19:38:44 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303193844-0004/1 on hostPort 10.128.4.237:43385 with 16 core(s), 64.0 GB RAM
2019-03-03 19:38:44 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303193844-0004/2 on worker-20190303170816-10.128.4.236-36408 (10.128.4.236:36408) with 16 core(s)
2019-03-03 19:38:44 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303193844-0004/2 on hostPort 10.128.4.236:36408 with 16 core(s), 64.0 GB RAM
2019-03-03 19:38:44 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303193844-0004/3 on worker-20190303170815-10.128.4.237-34711 (10.128.4.237:34711) with 16 core(s)
2019-03-03 19:38:44 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303193844-0004/3 on hostPort 10.128.4.237:34711 with 16 core(s), 64.0 GB RAM
2019-03-03 19:38:44 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40529.
2019-03-03 19:38:44 INFO  NettyBlockTransferService:54 - Server created on nid00797:40529
2019-03-03 19:38:44 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:38:44 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00797, 40529, None)
2019-03-03 19:38:44 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00797:40529 with 34.0 GB RAM, BlockManagerId(driver, nid00797, 40529, None)
2019-03-03 19:38:44 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00797, 40529, None)
2019-03-03 19:38:44 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00797, 40529, None)
2019-03-03 19:38:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:45 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 60
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 64
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 67108864
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 64000
Total Dependencies 190000
Total FLOPs 549755817984000
Total Bytes 0
Elapsed Time 4.696399e+02 seconds
FLOP/s 1.170590e+12
B/s 0.000000e+00
2019-03-03 19:54:45 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:54:45 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:54:46 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:54:46 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:54:46 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:54:46 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:54:46 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:54:46 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:54:46 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 41509.
2019-03-03 19:54:46 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:54:46 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:54:46 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:54:46 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:54:46 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-ff25f55f-9bc6-42a9-abc4-21346eaa66b9
2019-03-03 19:54:46 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:54:46 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:54:46 INFO  log:192 - Logging initialized @5433ms
2019-03-03 19:54:46 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:54:46 INFO  Server:414 - Started @5536ms
2019-03-03 19:54:46 INFO  AbstractConnector:278 - Started ServerConnector@779dfe55{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:54:46 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:54:46 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00797:4040
2019-03-03 19:54:47 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00797:41509/jars/Taskbench-assembly-1.0.jar with timestamp 1551671687007
2019-03-03 19:54:47 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00797:41509/files/libcore_c.so with timestamp 1551671687010
2019-03-03 19:54:47 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-29167981-e49c-4383-8f2e-990d0fcdc3a6/userFiles-7dc06f43-9cde-4a96-9569-9add5000f375/libcore_c.so
2019-03-03 19:54:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00797:7077...
2019-03-03 19:54:47 INFO  TransportClientFactory:267 - Successfully created connection to nid00797/10.128.3.36:7077 after 50 ms (0 ms spent in bootstraps)
2019-03-03 19:54:47 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303195447-0005
2019-03-03 19:54:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303195447-0005/0 on worker-20190303170816-10.128.4.236-34604 (10.128.4.236:34604) with 16 core(s)
2019-03-03 19:54:47 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303195447-0005/0 on hostPort 10.128.4.236:34604 with 16 core(s), 64.0 GB RAM
2019-03-03 19:54:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303195447-0005/1 on worker-20190303170815-10.128.4.237-43385 (10.128.4.237:43385) with 16 core(s)
2019-03-03 19:54:47 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303195447-0005/1 on hostPort 10.128.4.237:43385 with 16 core(s), 64.0 GB RAM
2019-03-03 19:54:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303195447-0005/2 on worker-20190303170816-10.128.4.236-36408 (10.128.4.236:36408) with 16 core(s)
2019-03-03 19:54:47 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303195447-0005/2 on hostPort 10.128.4.236:36408 with 16 core(s), 64.0 GB RAM
2019-03-03 19:54:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303195447-0005/3 on worker-20190303170815-10.128.4.237-34711 (10.128.4.237:34711) with 16 core(s)
2019-03-03 19:54:47 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303195447-0005/3 on hostPort 10.128.4.237:34711 with 16 core(s), 64.0 GB RAM
2019-03-03 19:54:47 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33605.
2019-03-03 19:54:47 INFO  NettyBlockTransferService:54 - Server created on nid00797:33605
2019-03-03 19:54:47 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:54:47 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00797, 33605, None)
2019-03-03 19:54:47 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00797:33605 with 34.0 GB RAM, BlockManagerId(driver, nid00797, 33605, None)
2019-03-03 19:54:47 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00797, 33605, None)
2019-03-03 19:54:47 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00797, 33605, None)
2019-03-03 19:54:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:54:47 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 60
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 64
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 67108864
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 64000
Total Dependencies 190000
Total FLOPs 549755817984000
Total Bytes 0
Elapsed Time 4.688173e+02 seconds
FLOP/s 1.172644e+12
B/s 0.000000e+00
2019-03-03 20:11:01 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:11:01 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:11:01 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:11:01 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:11:01 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:11:01 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:11:01 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:11:01 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:11:02 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 43277.
2019-03-03 20:11:02 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:11:02 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:11:02 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:11:02 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:11:02 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-e58887a7-3675-476c-a588-7fb40b823a48
2019-03-03 20:11:02 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:11:02 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:11:02 INFO  log:192 - Logging initialized @5253ms
2019-03-03 20:11:02 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:11:02 INFO  Server:414 - Started @5348ms
2019-03-03 20:11:02 INFO  AbstractConnector:278 - Started ServerConnector@4e69bcb9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:11:02 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:11:02 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00797:4040
2019-03-03 20:11:02 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00797:43277/jars/Taskbench-assembly-1.0.jar with timestamp 1551672662838
2019-03-03 20:11:02 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00797:43277/files/libcore_c.so with timestamp 1551672662842
2019-03-03 20:11:02 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-d94048ff-c2e7-4ca1-a37a-386686e03a52/userFiles-150301e0-8a29-4725-a751-7096bc4a1654/libcore_c.so
2019-03-03 20:11:03 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00797:7077...
2019-03-03 20:11:03 INFO  TransportClientFactory:267 - Successfully created connection to nid00797/10.128.3.36:7077 after 49 ms (0 ms spent in bootstraps)
2019-03-03 20:11:03 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303201103-0006
2019-03-03 20:11:03 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201103-0006/0 on worker-20190303170816-10.128.4.236-34604 (10.128.4.236:34604) with 16 core(s)
2019-03-03 20:11:03 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201103-0006/0 on hostPort 10.128.4.236:34604 with 16 core(s), 64.0 GB RAM
2019-03-03 20:11:03 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201103-0006/1 on worker-20190303170815-10.128.4.237-43385 (10.128.4.237:43385) with 16 core(s)
2019-03-03 20:11:03 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201103-0006/1 on hostPort 10.128.4.237:43385 with 16 core(s), 64.0 GB RAM
2019-03-03 20:11:03 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201103-0006/2 on worker-20190303170816-10.128.4.236-36408 (10.128.4.236:36408) with 16 core(s)
2019-03-03 20:11:03 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201103-0006/2 on hostPort 10.128.4.236:36408 with 16 core(s), 64.0 GB RAM
2019-03-03 20:11:03 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201103-0006/3 on worker-20190303170815-10.128.4.237-34711 (10.128.4.237:34711) with 16 core(s)
2019-03-03 20:11:03 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201103-0006/3 on hostPort 10.128.4.237:34711 with 16 core(s), 64.0 GB RAM
2019-03-03 20:11:03 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35616.
2019-03-03 20:11:03 INFO  NettyBlockTransferService:54 - Server created on nid00797:35616
2019-03-03 20:11:03 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:11:03 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00797, 35616, None)
2019-03-03 20:11:03 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00797:35616 with 34.0 GB RAM, BlockManagerId(driver, nid00797, 35616, None)
2019-03-03 20:11:03 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00797, 35616, None)
2019-03-03 20:11:03 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00797, 35616, None)
2019-03-03 20:11:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:03 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 60
Starting preprocessing
Starting warmup
Starting timing
