2019-03-02 16:39:13 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-02 16:39:13 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-02 16:39:13 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-02 16:39:13 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-02 16:39:13 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-02 16:39:13 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-02 16:39:13 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-02 16:39:13 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-02 16:39:14 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 38576.
2019-03-02 16:39:14 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-02 16:39:14 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-02 16:39:14 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-02 16:39:14 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-02 16:39:14 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-dbbba7f3-edda-4484-b9e3-cd9adba4a77b
2019-03-02 16:39:14 INFO  MemoryStore:54 - MemoryStore started with capacity 68.1 GB
2019-03-02 16:39:14 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-02 16:39:15 INFO  log:192 - Logging initialized @10323ms
2019-03-02 16:39:15 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-02 16:39:15 INFO  Server:414 - Started @10459ms
2019-03-02 16:39:15 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-02 16:39:15 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-02 16:39:15 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid12955:4040
2019-03-02 16:39:15 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid12955:38576/jars/Taskbench-assembly-1.0.jar with timestamp 1551573555671
2019-03-02 16:39:15 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid12955:38576/files/libcore_c.so with timestamp 1551573555674
2019-03-02 16:39:15 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-96845f24-eaa4-4b41-8406-479cc1618411/userFiles-8313350d-3e13-46f2-8359-7991de33c162/libcore_c.so
2019-03-02 16:39:15 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid12955:7077...
2019-03-02 16:39:15 INFO  TransportClientFactory:267 - Successfully created connection to nid12955/10.128.51.2:7077 after 48 ms (0 ms spent in bootstraps)
2019-03-02 16:39:16 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190302163916-0000
2019-03-02 16:39:16 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36835.
2019-03-02 16:39:16 INFO  NettyBlockTransferService:54 - Server created on nid12955:36835
2019-03-02 16:39:16 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-02 16:39:16 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid12955, 36835, None)
2019-03-02 16:39:16 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid12955:36835 with 68.1 GB RAM, BlockManagerId(driver, nid12955, 36835, None)
2019-03-02 16:39:16 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid12955, 36835, None)
2019-03-02 16:39:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302163916-0000/0 on worker-20190302163913-10.128.51.3-40194 (10.128.51.3:40194) with 16 core(s)
2019-03-02 16:39:16 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid12955, 36835, None)
2019-03-02 16:39:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302163916-0000/0 on hostPort 10.128.51.3:40194 with 16 core(s), 128.0 GB RAM
2019-03-02 16:39:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302163916-0000/1 on worker-20190302163913-10.128.51.3-36721 (10.128.51.3:36721) with 16 core(s)
2019-03-02 16:39:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302163916-0000/1 on hostPort 10.128.51.3:36721 with 16 core(s), 128.0 GB RAM
2019-03-02 16:39:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-02 16:39:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302163916-0000/0 is now RUNNING
2019-03-02 16:39:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302163916-0000/1 is now RUNNING
2019-03-02 16:39:16 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 268435456
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 94000
Total FLOPs 1099511629824000
Total Bytes 0
Elapsed Time 1.586819e+03 seconds
FLOP/s 6.929032e+11
B/s 0.000000e+00
2019-03-02 17:32:22 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-02 17:32:23 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-02 17:32:23 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-02 17:32:23 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-02 17:32:23 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-02 17:32:23 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-02 17:32:23 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-02 17:32:23 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-02 17:32:23 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40914.
2019-03-02 17:32:23 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-02 17:32:23 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-02 17:32:23 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-02 17:32:23 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-02 17:32:23 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-12c49719-6e1d-4c23-9013-7732baf28bcf
2019-03-02 17:32:23 INFO  MemoryStore:54 - MemoryStore started with capacity 68.1 GB
2019-03-02 17:32:23 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-02 17:32:24 INFO  log:192 - Logging initialized @7412ms
2019-03-02 17:32:24 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-02 17:32:24 INFO  Server:414 - Started @7532ms
2019-03-02 17:32:24 INFO  AbstractConnector:278 - Started ServerConnector@779dfe55{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-02 17:32:24 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-02 17:32:24 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid12955:4040
2019-03-02 17:32:24 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid12955:40914/jars/Taskbench-assembly-1.0.jar with timestamp 1551576744517
2019-03-02 17:32:24 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid12955:40914/files/libcore_c.so with timestamp 1551576744521
2019-03-02 17:32:24 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-9f47cf2c-7030-485b-aa41-75c8c3cf8e03/userFiles-b65fce22-7139-49b2-8152-01b4681c32c2/libcore_c.so
2019-03-02 17:32:24 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid12955:7077...
2019-03-02 17:32:24 INFO  TransportClientFactory:267 - Successfully created connection to nid12955/10.128.51.2:7077 after 49 ms (0 ms spent in bootstraps)
2019-03-02 17:32:24 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190302173224-0001
2019-03-02 17:32:24 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302173224-0001/0 on worker-20190302163913-10.128.51.3-40194 (10.128.51.3:40194) with 16 core(s)
2019-03-02 17:32:24 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302173224-0001/0 on hostPort 10.128.51.3:40194 with 16 core(s), 128.0 GB RAM
2019-03-02 17:32:24 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302173224-0001/1 on worker-20190302163913-10.128.51.3-36721 (10.128.51.3:36721) with 16 core(s)
2019-03-02 17:32:24 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302173224-0001/1 on hostPort 10.128.51.3:36721 with 16 core(s), 128.0 GB RAM
2019-03-02 17:32:24 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43669.
2019-03-02 17:32:24 INFO  NettyBlockTransferService:54 - Server created on nid12955:43669
2019-03-02 17:32:24 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-02 17:32:24 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid12955, 43669, None)
2019-03-02 17:32:24 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid12955:43669 with 68.1 GB RAM, BlockManagerId(driver, nid12955, 43669, None)
2019-03-02 17:32:24 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid12955, 43669, None)
2019-03-02 17:32:24 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid12955, 43669, None)
2019-03-02 17:32:25 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302173224-0001/1 is now RUNNING
2019-03-02 17:32:25 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302173224-0001/0 is now RUNNING
2019-03-02 17:32:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-02 17:32:25 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 134217728
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 94000
Total FLOPs 549755815936000
Total Bytes 0
Elapsed Time 8.119696e+02 seconds
FLOP/s 6.770645e+11
B/s 0.000000e+00
2019-03-02 17:59:45 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-02 17:59:46 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-02 17:59:46 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-02 17:59:46 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-02 17:59:46 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-02 17:59:46 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-02 17:59:46 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-02 17:59:46 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-02 17:59:47 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 39020.
2019-03-02 17:59:47 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-02 17:59:47 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-02 17:59:47 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-02 17:59:47 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-02 17:59:47 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-bb8484f4-ccd5-4edc-a343-34a80b9953f8
2019-03-02 17:59:47 INFO  MemoryStore:54 - MemoryStore started with capacity 68.1 GB
2019-03-02 17:59:47 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-02 17:59:47 INFO  log:192 - Logging initialized @6487ms
2019-03-02 17:59:47 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-02 17:59:47 INFO  Server:414 - Started @6601ms
2019-03-02 17:59:47 INFO  AbstractConnector:278 - Started ServerConnector@779dfe55{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-02 17:59:47 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-02 17:59:47 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid12955:4040
2019-03-02 17:59:47 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid12955:39020/jars/Taskbench-assembly-1.0.jar with timestamp 1551578387668
2019-03-02 17:59:47 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid12955:39020/files/libcore_c.so with timestamp 1551578387671
2019-03-02 17:59:47 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-68aff59e-a618-47e1-b198-fc8d8fde0763/userFiles-e810d5b0-ff44-4d07-a106-abf85f0a4aa0/libcore_c.so
2019-03-02 17:59:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid12955:7077...
2019-03-02 17:59:47 INFO  TransportClientFactory:267 - Successfully created connection to nid12955/10.128.51.2:7077 after 50 ms (0 ms spent in bootstraps)
2019-03-02 17:59:48 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190302175948-0002
2019-03-02 17:59:48 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302175948-0002/0 on worker-20190302163913-10.128.51.3-40194 (10.128.51.3:40194) with 16 core(s)
2019-03-02 17:59:48 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302175948-0002/0 on hostPort 10.128.51.3:40194 with 16 core(s), 128.0 GB RAM
2019-03-02 17:59:48 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302175948-0002/1 on worker-20190302163913-10.128.51.3-36721 (10.128.51.3:36721) with 16 core(s)
2019-03-02 17:59:48 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302175948-0002/1 on hostPort 10.128.51.3:36721 with 16 core(s), 128.0 GB RAM
2019-03-02 17:59:48 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42050.
2019-03-02 17:59:48 INFO  NettyBlockTransferService:54 - Server created on nid12955:42050
2019-03-02 17:59:48 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-02 17:59:48 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid12955, 42050, None)
2019-03-02 17:59:48 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid12955:42050 with 68.1 GB RAM, BlockManagerId(driver, nid12955, 42050, None)
2019-03-02 17:59:48 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid12955, 42050, None)
2019-03-02 17:59:48 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid12955, 42050, None)
2019-03-02 17:59:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-02 17:59:48 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 134217728
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 94000
Total FLOPs 549755815936000
Total Bytes 0
Elapsed Time 8.188279e+02 seconds
FLOP/s 6.713936e+11
B/s 0.000000e+00
2019-03-02 18:27:19 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-02 18:27:20 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-02 18:27:20 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-02 18:27:20 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-02 18:27:20 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-02 18:27:20 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-02 18:27:20 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-02 18:27:20 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-02 18:27:20 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35631.
2019-03-02 18:27:20 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-02 18:27:20 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-02 18:27:20 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-02 18:27:20 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-02 18:27:20 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-5db2c4ed-6bb7-4ea7-8673-0f5f0f034f77
2019-03-02 18:27:20 INFO  MemoryStore:54 - MemoryStore started with capacity 68.1 GB
2019-03-02 18:27:20 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-02 18:27:21 INFO  log:192 - Logging initialized @6283ms
2019-03-02 18:27:21 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-02 18:27:21 INFO  Server:414 - Started @6415ms
2019-03-02 18:27:21 INFO  AbstractConnector:278 - Started ServerConnector@67bb6d53{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-02 18:27:21 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-02 18:27:21 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid12955:4040
2019-03-02 18:27:21 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid12955:35631/jars/Taskbench-assembly-1.0.jar with timestamp 1551580041412
2019-03-02 18:27:21 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid12955:35631/files/libcore_c.so with timestamp 1551580041416
2019-03-02 18:27:21 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-8c9a1318-7910-4af7-bd0a-9e8738f772d1/userFiles-d45c0a8e-9204-41ce-bac0-c187ae548a4f/libcore_c.so
2019-03-02 18:27:21 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid12955:7077...
2019-03-02 18:27:21 INFO  TransportClientFactory:267 - Successfully created connection to nid12955/10.128.51.2:7077 after 52 ms (0 ms spent in bootstraps)
2019-03-02 18:27:21 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190302182721-0003
2019-03-02 18:27:21 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302182721-0003/0 on worker-20190302163913-10.128.51.3-40194 (10.128.51.3:40194) with 16 core(s)
2019-03-02 18:27:21 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302182721-0003/0 on hostPort 10.128.51.3:40194 with 16 core(s), 128.0 GB RAM
2019-03-02 18:27:21 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302182721-0003/1 on worker-20190302163913-10.128.51.3-36721 (10.128.51.3:36721) with 16 core(s)
2019-03-02 18:27:21 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302182721-0003/1 on hostPort 10.128.51.3:36721 with 16 core(s), 128.0 GB RAM
2019-03-02 18:27:21 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44540.
2019-03-02 18:27:21 INFO  NettyBlockTransferService:54 - Server created on nid12955:44540
2019-03-02 18:27:21 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-02 18:27:21 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid12955, 44540, None)
2019-03-02 18:27:21 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid12955:44540 with 68.1 GB RAM, BlockManagerId(driver, nid12955, 44540, None)
2019-03-02 18:27:21 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid12955, 44540, None)
2019-03-02 18:27:21 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid12955, 44540, None)
2019-03-02 18:27:22 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302182721-0003/0 is now RUNNING
2019-03-02 18:27:22 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302182721-0003/1 is now RUNNING
2019-03-02 18:27:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-02 18:27:22 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 67108864
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 94000
Total FLOPs 274877908992000
Total Bytes 0
Elapsed Time 4.252365e+02 seconds
FLOP/s 6.464118e+11
B/s 0.000000e+00
2019-03-02 18:41:56 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-02 18:41:57 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-02 18:41:57 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-02 18:41:57 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-02 18:41:57 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-02 18:41:57 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-02 18:41:57 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-02 18:41:57 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-02 18:41:57 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 36651.
2019-03-02 18:41:57 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-02 18:41:57 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-02 18:41:57 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-02 18:41:57 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-02 18:41:57 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-cfbeac1c-c473-4ece-96c7-6c28ad18de0e
2019-03-02 18:41:57 INFO  MemoryStore:54 - MemoryStore started with capacity 68.1 GB
2019-03-02 18:41:57 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-02 18:41:57 INFO  log:192 - Logging initialized @6738ms
2019-03-02 18:41:57 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-02 18:41:57 INFO  Server:414 - Started @6849ms
2019-03-02 18:41:58 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-02 18:41:58 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid12955:4040
2019-03-02 18:41:58 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid12955:36651/jars/Taskbench-assembly-1.0.jar with timestamp 1551580918176
2019-03-02 18:41:58 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid12955:36651/files/libcore_c.so with timestamp 1551580918179
2019-03-02 18:41:58 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-df58797e-bdb0-40ba-830b-440c0fda5afe/userFiles-4c4ae8c5-4155-4bca-b1ae-33c95675f83e/libcore_c.so
2019-03-02 18:41:58 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid12955:7077...
2019-03-02 18:41:58 INFO  TransportClientFactory:267 - Successfully created connection to nid12955/10.128.51.2:7077 after 53 ms (0 ms spent in bootstraps)
2019-03-02 18:41:58 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190302184158-0004
2019-03-02 18:41:58 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302184158-0004/0 on worker-20190302163913-10.128.51.3-40194 (10.128.51.3:40194) with 16 core(s)
2019-03-02 18:41:58 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302184158-0004/0 on hostPort 10.128.51.3:40194 with 16 core(s), 128.0 GB RAM
2019-03-02 18:41:58 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302184158-0004/1 on worker-20190302163913-10.128.51.3-36721 (10.128.51.3:36721) with 16 core(s)
2019-03-02 18:41:58 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302184158-0004/1 on hostPort 10.128.51.3:36721 with 16 core(s), 128.0 GB RAM
2019-03-02 18:41:58 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45074.
2019-03-02 18:41:58 INFO  NettyBlockTransferService:54 - Server created on nid12955:45074
2019-03-02 18:41:58 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-02 18:41:58 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid12955, 45074, None)
2019-03-02 18:41:58 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid12955:45074 with 68.1 GB RAM, BlockManagerId(driver, nid12955, 45074, None)
2019-03-02 18:41:58 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid12955, 45074, None)
2019-03-02 18:41:58 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid12955, 45074, None)
2019-03-02 18:41:58 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302184158-0004/1 is now RUNNING
2019-03-02 18:41:58 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302184158-0004/0 is now RUNNING
2019-03-02 18:41:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-02 18:41:58 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 67108864
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 94000
Total FLOPs 274877908992000
Total Bytes 0
Elapsed Time 4.262053e+02 seconds
FLOP/s 6.449424e+11
B/s 0.000000e+00
2019-03-02 18:56:33 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-02 18:56:34 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-02 18:56:34 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-02 18:56:34 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-02 18:56:34 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-02 18:56:34 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-02 18:56:34 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-02 18:56:34 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-02 18:56:35 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40251.
2019-03-02 18:56:35 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-02 18:56:35 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-02 18:56:35 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-02 18:56:35 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-02 18:56:35 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-5bc4c6e0-d43e-4607-aebf-461d55e99105
2019-03-02 18:56:35 INFO  MemoryStore:54 - MemoryStore started with capacity 68.1 GB
2019-03-02 18:56:35 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-02 18:56:35 INFO  log:192 - Logging initialized @6981ms
2019-03-02 18:56:35 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-02 18:56:35 INFO  Server:414 - Started @7095ms
2019-03-02 18:56:35 INFO  AbstractConnector:278 - Started ServerConnector@7f8fbc1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-02 18:56:35 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-02 18:56:35 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid12955:4040
2019-03-02 18:56:35 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid12955:40251/jars/Taskbench-assembly-1.0.jar with timestamp 1551581795916
2019-03-02 18:56:35 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid12955:40251/files/libcore_c.so with timestamp 1551581795919
2019-03-02 18:56:35 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-406b33be-b70d-4b79-b4c8-c1a1af37ae12/userFiles-d942bb49-569a-43e0-98ef-0fbb0b0347f4/libcore_c.so
2019-03-02 18:56:36 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid12955:7077...
2019-03-02 18:56:36 INFO  TransportClientFactory:267 - Successfully created connection to nid12955/10.128.51.2:7077 after 50 ms (0 ms spent in bootstraps)
2019-03-02 18:56:36 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190302185636-0005
2019-03-02 18:56:36 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302185636-0005/0 on worker-20190302163913-10.128.51.3-40194 (10.128.51.3:40194) with 16 core(s)
2019-03-02 18:56:36 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302185636-0005/0 on hostPort 10.128.51.3:40194 with 16 core(s), 128.0 GB RAM
2019-03-02 18:56:36 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302185636-0005/1 on worker-20190302163913-10.128.51.3-36721 (10.128.51.3:36721) with 16 core(s)
2019-03-02 18:56:36 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302185636-0005/1 on hostPort 10.128.51.3:36721 with 16 core(s), 128.0 GB RAM
2019-03-02 18:56:36 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39250.
2019-03-02 18:56:36 INFO  NettyBlockTransferService:54 - Server created on nid12955:39250
2019-03-02 18:56:36 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-02 18:56:36 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid12955, 39250, None)
2019-03-02 18:56:36 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid12955:39250 with 68.1 GB RAM, BlockManagerId(driver, nid12955, 39250, None)
2019-03-02 18:56:36 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid12955, 39250, None)
2019-03-02 18:56:36 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid12955, 39250, None)
2019-03-02 18:56:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-02 18:56:36 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 67108864
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 94000
Total FLOPs 274877908992000
Total Bytes 0
Elapsed Time 4.303935e+02 seconds
FLOP/s 6.386665e+11
B/s 0.000000e+00
2019-03-02 19:11:18 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-02 19:11:19 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-02 19:11:19 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-02 19:11:19 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-02 19:11:19 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-02 19:11:19 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-02 19:11:19 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-02 19:11:19 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-02 19:11:19 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40870.
2019-03-02 19:11:20 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-02 19:11:20 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-02 19:11:20 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-02 19:11:20 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-02 19:11:20 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-89fd8228-290d-41c3-9a3a-757bb5e43baf
2019-03-02 19:11:20 INFO  MemoryStore:54 - MemoryStore started with capacity 68.1 GB
2019-03-02 19:11:20 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-02 19:11:20 INFO  log:192 - Logging initialized @9062ms
2019-03-02 19:11:20 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-02 19:11:20 INFO  Server:414 - Started @9189ms
2019-03-02 19:11:20 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-02 19:11:20 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-02 19:11:20 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid12955:4040
2019-03-02 19:11:20 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid12955:40870/jars/Taskbench-assembly-1.0.jar with timestamp 1551582680701
2019-03-02 19:11:20 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid12955:40870/files/libcore_c.so with timestamp 1551582680705
2019-03-02 19:11:20 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-8794734a-dd5b-45e0-9700-1bb680bba249/userFiles-580eee44-ee51-4788-8ca0-5ec0d6ae5ad8/libcore_c.so
2019-03-02 19:11:20 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid12955:7077...
2019-03-02 19:11:20 INFO  TransportClientFactory:267 - Successfully created connection to nid12955/10.128.51.2:7077 after 50 ms (0 ms spent in bootstraps)
2019-03-02 19:11:21 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190302191121-0006
2019-03-02 19:11:21 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302191121-0006/0 on worker-20190302163913-10.128.51.3-40194 (10.128.51.3:40194) with 16 core(s)
2019-03-02 19:11:21 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302191121-0006/0 on hostPort 10.128.51.3:40194 with 16 core(s), 128.0 GB RAM
2019-03-02 19:11:21 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302191121-0006/1 on worker-20190302163913-10.128.51.3-36721 (10.128.51.3:36721) with 16 core(s)
2019-03-02 19:11:21 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302191121-0006/1 on hostPort 10.128.51.3:36721 with 16 core(s), 128.0 GB RAM
2019-03-02 19:11:21 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39047.
2019-03-02 19:11:21 INFO  NettyBlockTransferService:54 - Server created on nid12955:39047
2019-03-02 19:11:21 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-02 19:11:21 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid12955, 39047, None)
2019-03-02 19:11:21 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid12955:39047 with 68.1 GB RAM, BlockManagerId(driver, nid12955, 39047, None)
2019-03-02 19:11:21 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid12955, 39047, None)
2019-03-02 19:11:21 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid12955, 39047, None)
2019-03-02 19:11:21 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302191121-0006/1 is now RUNNING
2019-03-02 19:11:21 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302191121-0006/0 is now RUNNING
2019-03-02 19:11:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-02 19:11:21 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 33554432
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 94000
Total FLOPs 137438955520000
Total Bytes 0
Elapsed Time 2.368596e+02 seconds
FLOP/s 5.802549e+11
B/s 0.000000e+00
2019-03-02 19:19:38 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-02 19:19:39 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-02 19:19:39 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-02 19:19:39 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-02 19:19:39 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-02 19:19:39 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-02 19:19:39 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-02 19:19:39 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-02 19:19:40 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 36332.
2019-03-02 19:19:40 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-02 19:19:40 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-02 19:19:40 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-02 19:19:40 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-02 19:19:40 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-b655e45a-abbf-466d-9899-966b1b16b8e4
2019-03-02 19:19:40 INFO  MemoryStore:54 - MemoryStore started with capacity 68.1 GB
2019-03-02 19:19:40 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-02 19:19:40 INFO  log:192 - Logging initialized @9103ms
2019-03-02 19:19:40 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-02 19:19:40 INFO  Server:414 - Started @9231ms
2019-03-02 19:19:40 INFO  AbstractConnector:278 - Started ServerConnector@779dfe55{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-02 19:19:40 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-02 19:19:40 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid12955:4040
2019-03-02 19:19:40 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid12955:36332/jars/Taskbench-assembly-1.0.jar with timestamp 1551583180889
2019-03-02 19:19:40 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid12955:36332/files/libcore_c.so with timestamp 1551583180892
2019-03-02 19:19:40 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-9629367c-f63d-4893-9493-7df0a0fc1945/userFiles-ecdffffe-2af1-44a5-9898-8648554e3778/libcore_c.so
2019-03-02 19:19:41 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid12955:7077...
2019-03-02 19:19:41 INFO  TransportClientFactory:267 - Successfully created connection to nid12955/10.128.51.2:7077 after 89 ms (0 ms spent in bootstraps)
2019-03-02 19:19:41 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190302191941-0007
2019-03-02 19:19:41 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302191941-0007/0 on worker-20190302163913-10.128.51.3-40194 (10.128.51.3:40194) with 16 core(s)
2019-03-02 19:19:41 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302191941-0007/0 on hostPort 10.128.51.3:40194 with 16 core(s), 128.0 GB RAM
2019-03-02 19:19:41 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302191941-0007/1 on worker-20190302163913-10.128.51.3-36721 (10.128.51.3:36721) with 16 core(s)
2019-03-02 19:19:41 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302191941-0007/1 on hostPort 10.128.51.3:36721 with 16 core(s), 128.0 GB RAM
2019-03-02 19:19:41 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46515.
2019-03-02 19:19:41 INFO  NettyBlockTransferService:54 - Server created on nid12955:46515
2019-03-02 19:19:41 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-02 19:19:41 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid12955, 46515, None)
2019-03-02 19:19:41 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid12955:46515 with 68.1 GB RAM, BlockManagerId(driver, nid12955, 46515, None)
2019-03-02 19:19:41 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid12955, 46515, None)
2019-03-02 19:19:41 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid12955, 46515, None)
2019-03-02 19:19:41 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302191941-0007/1 is now RUNNING
2019-03-02 19:19:41 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302191941-0007/0 is now RUNNING
2019-03-02 19:19:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-02 19:19:41 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 33554432
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 94000
Total FLOPs 137438955520000
Total Bytes 0
Elapsed Time 2.340284e+02 seconds
FLOP/s 5.872747e+11
B/s 0.000000e+00
2019-03-02 19:27:50 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-02 19:27:51 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-02 19:27:51 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-02 19:27:51 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-02 19:27:51 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-02 19:27:51 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-02 19:27:51 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-02 19:27:51 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-02 19:27:52 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35102.
2019-03-02 19:27:52 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-02 19:27:52 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-02 19:27:52 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-02 19:27:52 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-02 19:27:52 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-ba89bf67-fd43-4aa3-bf6c-138478b5875c
2019-03-02 19:27:52 INFO  MemoryStore:54 - MemoryStore started with capacity 68.1 GB
2019-03-02 19:27:52 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-02 19:27:52 INFO  log:192 - Logging initialized @7937ms
2019-03-02 19:27:52 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-02 19:27:52 INFO  Server:414 - Started @8049ms
2019-03-02 19:27:52 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-02 19:27:52 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-02 19:27:52 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid12955:4040
2019-03-02 19:27:53 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid12955:35102/jars/Taskbench-assembly-1.0.jar with timestamp 1551583673049
2019-03-02 19:27:53 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid12955:35102/files/libcore_c.so with timestamp 1551583673052
2019-03-02 19:27:53 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-e5b82f47-0e76-458a-9a37-b04cc7a75d60/userFiles-e87a0787-9825-40d0-805f-09bb05c8dc2e/libcore_c.so
2019-03-02 19:27:53 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid12955:7077...
2019-03-02 19:27:53 INFO  TransportClientFactory:267 - Successfully created connection to nid12955/10.128.51.2:7077 after 58 ms (0 ms spent in bootstraps)
2019-03-02 19:27:53 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190302192753-0008
2019-03-02 19:27:53 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302192753-0008/0 on worker-20190302163913-10.128.51.3-40194 (10.128.51.3:40194) with 16 core(s)
2019-03-02 19:27:53 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302192753-0008/0 on hostPort 10.128.51.3:40194 with 16 core(s), 128.0 GB RAM
2019-03-02 19:27:53 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302192753-0008/1 on worker-20190302163913-10.128.51.3-36721 (10.128.51.3:36721) with 16 core(s)
2019-03-02 19:27:53 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302192753-0008/1 on hostPort 10.128.51.3:36721 with 16 core(s), 128.0 GB RAM
2019-03-02 19:27:53 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44863.
2019-03-02 19:27:53 INFO  NettyBlockTransferService:54 - Server created on nid12955:44863
2019-03-02 19:27:53 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-02 19:27:53 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid12955, 44863, None)
2019-03-02 19:27:53 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid12955:44863 with 68.1 GB RAM, BlockManagerId(driver, nid12955, 44863, None)
2019-03-02 19:27:53 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid12955, 44863, None)
2019-03-02 19:27:53 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid12955, 44863, None)
2019-03-02 19:27:53 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302192753-0008/1 is now RUNNING
2019-03-02 19:27:53 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302192753-0008/0 is now RUNNING
2019-03-02 19:27:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-02 19:27:53 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: stencil_1d
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 33554432
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 94000
Total FLOPs 137438955520000
Total Bytes 0
Elapsed Time 2.342633e+02 seconds
FLOP/s 5.866858e+11
B/s 0.000000e+00
2019-03-02 19:36:05 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-02 19:36:06 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-02 19:36:06 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-02 19:36:06 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-02 19:36:06 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-02 19:36:06 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-02 19:36:06 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-02 19:36:06 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-02 19:36:06 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 43618.
2019-03-02 19:36:07 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-02 19:36:07 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-02 19:36:07 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-02 19:36:07 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-02 19:36:07 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-ca7815a6-1d9a-4ca8-ad37-971be491a776
2019-03-02 19:36:07 INFO  MemoryStore:54 - MemoryStore started with capacity 68.1 GB
2019-03-02 19:36:07 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-02 19:36:07 INFO  log:192 - Logging initialized @8822ms
2019-03-02 19:36:07 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-02 19:36:07 INFO  Server:414 - Started @8934ms
2019-03-02 19:36:07 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-02 19:36:07 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-02 19:36:07 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid12955:4040
2019-03-02 19:36:07 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid12955:43618/jars/Taskbench-assembly-1.0.jar with timestamp 1551584167597
2019-03-02 19:36:07 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid12955:43618/files/libcore_c.so with timestamp 1551584167600
2019-03-02 19:36:07 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-265be8b6-6e9c-41cd-a4c0-680610781e2f/userFiles-84930a66-340b-4a5c-9dcb-89877ac14abf/libcore_c.so
2019-03-02 19:36:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid12955:7077...
2019-03-02 19:36:07 INFO  TransportClientFactory:267 - Successfully created connection to nid12955/10.128.51.2:7077 after 54 ms (0 ms spent in bootstraps)
2019-03-02 19:36:07 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190302193607-0009
2019-03-02 19:36:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302193607-0009/0 on worker-20190302163913-10.128.51.3-40194 (10.128.51.3:40194) with 16 core(s)
2019-03-02 19:36:07 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302193607-0009/0 on hostPort 10.128.51.3:40194 with 16 core(s), 128.0 GB RAM
2019-03-02 19:36:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190302193607-0009/1 on worker-20190302163913-10.128.51.3-36721 (10.128.51.3:36721) with 16 core(s)
2019-03-02 19:36:07 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190302193607-0009/1 on hostPort 10.128.51.3:36721 with 16 core(s), 128.0 GB RAM
2019-03-02 19:36:07 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42884.
2019-03-02 19:36:07 INFO  NettyBlockTransferService:54 - Server created on nid12955:42884
2019-03-02 19:36:07 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-02 19:36:07 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid12955, 42884, None)
2019-03-02 19:36:07 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid12955:42884 with 68.1 GB RAM, BlockManagerId(driver, nid12955, 42884, None)
2019-03-02 19:36:07 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid12955, 42884, None)
2019-03-02 19:36:07 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid12955, 42884, None)
2019-03-02 19:36:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-02 19:36:08 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2019-03-02 19:36:08 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302193607-0009/1 is now RUNNING
2019-03-02 19:36:08 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190302193607-0009/0 is now RUNNING
Num partitions: 30
Starting preprocessing
Starting warmup
