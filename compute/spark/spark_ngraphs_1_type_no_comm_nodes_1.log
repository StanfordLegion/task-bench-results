2019-03-03 16:40:29 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 16:40:29 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 16:40:29 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 16:40:30 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 16:40:30 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 16:40:30 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 16:40:30 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 16:40:30 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 16:40:30 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 34955.
2019-03-03 16:40:30 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 16:40:30 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 16:40:30 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 16:40:30 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 16:40:30 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-90837fd3-462d-4b78-b5ca-562629a5e6ec
2019-03-03 16:40:30 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 16:40:30 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 16:40:30 INFO  log:192 - Logging initialized @5309ms
2019-03-03 16:40:31 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 16:40:31 INFO  Server:414 - Started @5417ms
2019-03-03 16:40:31 INFO  AbstractConnector:278 - Started ServerConnector@1dcee834{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 16:40:31 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 16:40:31 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 16:40:31 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:34955/jars/Taskbench-assembly-1.0.jar with timestamp 1551660031254
2019-03-03 16:40:31 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:34955/files/libcore_c.so with timestamp 1551660031258
2019-03-03 16:40:31 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-edf64176-2f7d-408d-9fe9-3041eda705e0/userFiles-3b18c032-e9e7-4b3d-9413-e60bf81fed08/libcore_c.so
2019-03-03 16:40:31 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 16:40:31 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 49 ms (0 ms spent in bootstraps)
2019-03-03 16:40:31 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303164031-0000
2019-03-03 16:40:31 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34391.
2019-03-03 16:40:31 INFO  NettyBlockTransferService:54 - Server created on nid00963:34391
2019-03-03 16:40:31 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 16:40:31 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 34391, None)
2019-03-03 16:40:31 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:34391 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 34391, None)
2019-03-03 16:40:31 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 34391, None)
2019-03-03 16:40:31 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 34391, None)
2019-03-03 16:40:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 16:40:32 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 268435456
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 1099511629824000
Total Bytes 0
Elapsed Time 1.528508e+03 seconds
FLOP/s 7.193368e+11
B/s 0.000000e+00
2019-03-03 17:32:05 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 17:32:06 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 17:32:06 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 17:32:06 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 17:32:06 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 17:32:06 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 17:32:06 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 17:32:06 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 17:32:06 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 36580.
2019-03-03 17:32:06 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 17:32:06 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 17:32:06 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 17:32:06 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 17:32:06 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-17295868-57f3-487b-9254-1caadd66329c
2019-03-03 17:32:06 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 17:32:06 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 17:32:06 INFO  log:192 - Logging initialized @4358ms
2019-03-03 17:32:07 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 17:32:07 INFO  Server:414 - Started @4458ms
2019-03-03 17:32:07 INFO  AbstractConnector:278 - Started ServerConnector@5a526f77{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 17:32:07 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@127d7908{/jobs,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/static,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/api,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 17:32:07 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:36580/jars/Taskbench-assembly-1.0.jar with timestamp 1551663127200
2019-03-03 17:32:07 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:36580/files/libcore_c.so with timestamp 1551663127203
2019-03-03 17:32:07 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-09e4e547-b4f6-499f-8933-25b2f42815e5/userFiles-f9c36520-2e57-40ce-9d35-f748fe105ef9/libcore_c.so
2019-03-03 17:32:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 17:32:07 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 48 ms (0 ms spent in bootstraps)
2019-03-03 17:32:07 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303173207-0001
2019-03-03 17:32:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303173207-0001/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 17:32:07 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303173207-0001/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 17:32:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303173207-0001/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 17:32:07 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303173207-0001/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 17:32:07 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40339.
2019-03-03 17:32:07 INFO  NettyBlockTransferService:54 - Server created on nid00963:40339
2019-03-03 17:32:07 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 17:32:07 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 40339, None)
2019-03-03 17:32:07 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:40339 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 40339, None)
2019-03-03 17:32:07 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 40339, None)
2019-03-03 17:32:07 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 40339, None)
2019-03-03 17:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@58294867{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 17:32:07 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 134217728
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 549755815936000
Total Bytes 0
Elapsed Time 7.670805e+02 seconds
FLOP/s 7.166859e+11
B/s 0.000000e+00
2019-03-03 17:58:19 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 17:58:20 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 17:58:20 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 17:58:20 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 17:58:20 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 17:58:20 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 17:58:20 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 17:58:20 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 17:58:21 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 43964.
2019-03-03 17:58:21 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 17:58:21 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 17:58:21 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 17:58:21 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 17:58:21 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-c54d2232-f6ef-4056-ab57-18b6ca9ac69f
2019-03-03 17:58:21 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 17:58:21 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 17:58:21 INFO  log:192 - Logging initialized @7298ms
2019-03-03 17:58:21 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 17:58:21 INFO  Server:414 - Started @7405ms
2019-03-03 17:58:21 INFO  AbstractConnector:278 - Started ServerConnector@779dfe55{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 17:58:21 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 17:58:21 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 17:58:21 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:43964/jars/Taskbench-assembly-1.0.jar with timestamp 1551664701947
2019-03-03 17:58:21 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:43964/files/libcore_c.so with timestamp 1551664701951
2019-03-03 17:58:21 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-2f4c3022-169a-4cbe-9f0d-87c31d6456d6/userFiles-896dc2a8-fac9-455c-bc17-20d9ec24b536/libcore_c.so
2019-03-03 17:58:22 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 17:58:22 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 50 ms (0 ms spent in bootstraps)
2019-03-03 17:58:22 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303175822-0002
2019-03-03 17:58:22 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303175822-0002/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 17:58:22 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303175822-0002/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 17:58:22 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303175822-0002/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 17:58:22 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303175822-0002/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 17:58:22 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33777.
2019-03-03 17:58:22 INFO  NettyBlockTransferService:54 - Server created on nid00963:33777
2019-03-03 17:58:22 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 17:58:22 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 33777, None)
2019-03-03 17:58:22 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:33777 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 33777, None)
2019-03-03 17:58:22 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 33777, None)
2019-03-03 17:58:22 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 33777, None)
2019-03-03 17:58:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 17:58:22 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 134217728
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 549755815936000
Total Bytes 0
Elapsed Time 7.688685e+02 seconds
FLOP/s 7.150193e+11
B/s 0.000000e+00
2019-03-03 18:24:42 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 18:24:42 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 18:24:42 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 18:24:43 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 18:24:43 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 18:24:43 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 18:24:43 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 18:24:43 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 18:24:43 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 37706.
2019-03-03 18:24:43 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 18:24:43 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 18:24:43 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 18:24:43 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 18:24:43 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-b885db3c-720c-41c9-a7e7-e93da4aea979
2019-03-03 18:24:43 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 18:24:43 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 18:24:43 INFO  log:192 - Logging initialized @4862ms
2019-03-03 18:24:43 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 18:24:43 INFO  Server:414 - Started @4958ms
2019-03-03 18:24:43 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 18:24:43 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 18:24:43 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 18:24:44 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:37706/jars/Taskbench-assembly-1.0.jar with timestamp 1551666284000
2019-03-03 18:24:44 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:37706/files/libcore_c.so with timestamp 1551666284003
2019-03-03 18:24:44 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-e7e898b1-1521-4d15-a665-c99f8b5be118/userFiles-00f24152-a546-42fa-84d3-86563c7d2156/libcore_c.so
2019-03-03 18:24:44 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 18:24:44 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 49 ms (0 ms spent in bootstraps)
2019-03-03 18:24:44 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303182444-0003
2019-03-03 18:24:44 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303182444-0003/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 18:24:44 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303182444-0003/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 18:24:44 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303182444-0003/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 18:24:44 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303182444-0003/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 18:24:44 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37390.
2019-03-03 18:24:44 INFO  NettyBlockTransferService:54 - Server created on nid00963:37390
2019-03-03 18:24:44 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 18:24:44 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 37390, None)
2019-03-03 18:24:44 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:37390 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 37390, None)
2019-03-03 18:24:44 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 37390, None)
2019-03-03 18:24:44 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 37390, None)
2019-03-03 18:24:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 18:24:44 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 67108864
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 274877908992000
Total Bytes 0
Elapsed Time 3.873880e+02 seconds
FLOP/s 7.095674e+11
B/s 0.000000e+00
2019-03-03 18:38:23 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 18:38:23 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 18:38:23 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 18:38:24 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 18:38:24 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 18:38:24 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 18:38:24 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 18:38:24 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 18:38:24 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 41630.
2019-03-03 18:38:24 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 18:38:24 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 18:38:24 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 18:38:24 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 18:38:24 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-c68157ba-d41e-4945-912e-dde342981a09
2019-03-03 18:38:24 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 18:38:24 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 18:38:24 INFO  log:192 - Logging initialized @4662ms
2019-03-03 18:38:24 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 18:38:24 INFO  Server:414 - Started @4759ms
2019-03-03 18:38:24 INFO  AbstractConnector:278 - Started ServerConnector@2ac1270c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 18:38:24 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 18:38:24 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 18:38:24 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:41630/jars/Taskbench-assembly-1.0.jar with timestamp 1551667104987
2019-03-03 18:38:24 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:41630/files/libcore_c.so with timestamp 1551667104990
2019-03-03 18:38:24 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-368f345b-d53a-46c3-a22e-04f83553b05e/userFiles-23d3913b-73de-45e8-9e8e-2de5b78c5c8f/libcore_c.so
2019-03-03 18:38:25 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 18:38:25 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 47 ms (0 ms spent in bootstraps)
2019-03-03 18:38:27 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303183827-0004
2019-03-03 18:38:27 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303183827-0004/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 18:38:27 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303183827-0004/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 18:38:27 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303183827-0004/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 18:38:27 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303183827-0004/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 18:38:27 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37028.
2019-03-03 18:38:27 INFO  NettyBlockTransferService:54 - Server created on nid00963:37028
2019-03-03 18:38:27 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 18:38:27 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 37028, None)
2019-03-03 18:38:27 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:37028 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 37028, None)
2019-03-03 18:38:27 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 37028, None)
2019-03-03 18:38:27 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 37028, None)
2019-03-03 18:38:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 18:38:27 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 67108864
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 274877908992000
Total Bytes 0
Elapsed Time 3.888478e+02 seconds
FLOP/s 7.069037e+11
B/s 0.000000e+00
2019-03-03 18:51:57 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 18:51:58 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 18:51:58 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 18:51:58 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 18:51:58 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 18:51:58 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 18:51:58 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 18:51:58 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 18:51:58 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35526.
2019-03-03 18:51:58 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 18:51:58 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 18:51:58 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 18:51:58 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 18:51:58 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-4ac4425c-ded6-4c83-8532-8004ad5b9a4f
2019-03-03 18:51:58 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 18:51:58 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 18:51:59 INFO  log:192 - Logging initialized @4046ms
2019-03-03 18:51:59 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 18:51:59 INFO  Server:414 - Started @4148ms
2019-03-03 18:51:59 INFO  AbstractConnector:278 - Started ServerConnector@163cc4b3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 18:51:59 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 18:51:59 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:35526/jars/Taskbench-assembly-1.0.jar with timestamp 1551667919272
2019-03-03 18:51:59 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:35526/files/libcore_c.so with timestamp 1551667919275
2019-03-03 18:51:59 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-5093ddce-461c-4566-9e48-a8db2d9e4166/userFiles-df861a7c-289e-4654-b4ad-af4ddcccb13f/libcore_c.so
2019-03-03 18:51:59 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 18:51:59 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 47 ms (0 ms spent in bootstraps)
2019-03-03 18:51:59 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303185159-0005
2019-03-03 18:51:59 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303185159-0005/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 18:51:59 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303185159-0005/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 18:51:59 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303185159-0005/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 18:51:59 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303185159-0005/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 18:51:59 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42300.
2019-03-03 18:51:59 INFO  NettyBlockTransferService:54 - Server created on nid00963:42300
2019-03-03 18:51:59 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 18:51:59 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 42300, None)
2019-03-03 18:51:59 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:42300 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 42300, None)
2019-03-03 18:51:59 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 42300, None)
2019-03-03 18:51:59 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 42300, None)
2019-03-03 18:51:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 18:51:59 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 67108864
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 274877908992000
Total Bytes 0
Elapsed Time 3.886549e+02 seconds
FLOP/s 7.072545e+11
B/s 0.000000e+00
2019-03-03 19:05:42 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:05:42 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:05:42 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:05:43 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:05:43 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:05:43 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:05:43 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:05:43 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:05:43 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 44199.
2019-03-03 19:05:43 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:05:43 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:05:43 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:05:43 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:05:43 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-128c5bee-ac7a-4925-8e7e-04c066cc716c
2019-03-03 19:05:43 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:05:43 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:05:43 INFO  log:192 - Logging initialized @5817ms
2019-03-03 19:05:43 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:05:43 INFO  Server:414 - Started @5915ms
2019-03-03 19:05:43 INFO  AbstractConnector:278 - Started ServerConnector@67bb6d53{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:05:43 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@127d7908{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:05:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/static,null,AVAILABLE,@Spark}
2019-03-03 19:05:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/,null,AVAILABLE,@Spark}
2019-03-03 19:05:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/api,null,AVAILABLE,@Spark}
2019-03-03 19:05:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:05:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:05:44 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 19:05:44 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:44199/jars/Taskbench-assembly-1.0.jar with timestamp 1551668744080
2019-03-03 19:05:44 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:44199/files/libcore_c.so with timestamp 1551668744083
2019-03-03 19:05:44 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-51cb1f5d-4606-4871-aa78-e899ced73396/userFiles-cdd97d98-6c02-4c75-a1f2-6113e3fdb058/libcore_c.so
2019-03-03 19:05:44 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 19:05:44 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 47 ms (0 ms spent in bootstraps)
2019-03-03 19:05:44 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303190544-0006
2019-03-03 19:05:44 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303190544-0006/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 19:05:44 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303190544-0006/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 19:05:44 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303190544-0006/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 19:05:44 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303190544-0006/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 19:05:44 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42459.
2019-03-03 19:05:44 INFO  NettyBlockTransferService:54 - Server created on nid00963:42459
2019-03-03 19:05:44 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:05:44 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 42459, None)
2019-03-03 19:05:44 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:42459 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 42459, None)
2019-03-03 19:05:44 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 42459, None)
2019-03-03 19:05:44 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 42459, None)
2019-03-03 19:05:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@58294867{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:05:44 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 33554432
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 137438955520000
Total Bytes 0
Elapsed Time 1.981823e+02 seconds
FLOP/s 6.934977e+11
B/s 0.000000e+00
2019-03-03 19:13:00 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:13:01 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:13:01 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:13:01 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:13:01 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:13:01 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:13:01 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:13:01 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:13:01 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 45313.
2019-03-03 19:13:01 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:13:01 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:13:01 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:13:01 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:13:01 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-e103ae87-4ba1-4919-9ee4-ff683254d2cb
2019-03-03 19:13:01 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:13:02 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:13:02 INFO  log:192 - Logging initialized @4199ms
2019-03-03 19:13:02 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:13:02 INFO  Server:414 - Started @4297ms
2019-03-03 19:13:02 INFO  AbstractConnector:278 - Started ServerConnector@779dfe55{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:13:02 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 19:13:02 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:45313/jars/Taskbench-assembly-1.0.jar with timestamp 1551669182377
2019-03-03 19:13:02 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:45313/files/libcore_c.so with timestamp 1551669182380
2019-03-03 19:13:02 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-56b4b6fe-c7fd-4958-9079-793be2637e33/userFiles-c0c173fd-93ed-40d2-9260-df4d7ef0084e/libcore_c.so
2019-03-03 19:13:02 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 19:13:02 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 51 ms (0 ms spent in bootstraps)
2019-03-03 19:13:02 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303191302-0007
2019-03-03 19:13:02 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303191302-0007/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 19:13:02 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303191302-0007/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 19:13:02 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303191302-0007/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 19:13:02 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303191302-0007/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 19:13:02 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36536.
2019-03-03 19:13:02 INFO  NettyBlockTransferService:54 - Server created on nid00963:36536
2019-03-03 19:13:02 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:13:02 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 36536, None)
2019-03-03 19:13:02 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:36536 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 36536, None)
2019-03-03 19:13:02 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 36536, None)
2019-03-03 19:13:02 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 36536, None)
2019-03-03 19:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:13:02 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 33554432
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 137438955520000
Total Bytes 0
Elapsed Time 1.981062e+02 seconds
FLOP/s 6.937641e+11
B/s 0.000000e+00
2019-03-03 19:20:05 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:20:06 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:20:06 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:20:06 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:20:06 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:20:06 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:20:06 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:20:06 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:20:06 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 39507.
2019-03-03 19:20:06 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:20:06 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:20:06 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:20:06 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:20:06 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-c591cc39-8e5b-44fe-91f6-3cb8ecf56e39
2019-03-03 19:20:06 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:20:06 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:20:07 INFO  log:192 - Logging initialized @5468ms
2019-03-03 19:20:07 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:20:07 INFO  Server:414 - Started @5579ms
2019-03-03 19:20:07 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:20:07 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 19:20:07 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:39507/jars/Taskbench-assembly-1.0.jar with timestamp 1551669607349
2019-03-03 19:20:07 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:39507/files/libcore_c.so with timestamp 1551669607352
2019-03-03 19:20:07 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-6681f70c-be7e-4586-bca1-0764e484732f/userFiles-3295ada8-e6d9-4ae1-b3bb-5a32fabe9926/libcore_c.so
2019-03-03 19:20:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 19:20:07 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 50 ms (0 ms spent in bootstraps)
2019-03-03 19:20:07 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303192007-0008
2019-03-03 19:20:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303192007-0008/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 19:20:07 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303192007-0008/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 19:20:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303192007-0008/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 19:20:07 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303192007-0008/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 19:20:07 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38377.
2019-03-03 19:20:07 INFO  NettyBlockTransferService:54 - Server created on nid00963:38377
2019-03-03 19:20:07 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:20:07 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 38377, None)
2019-03-03 19:20:07 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:38377 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 38377, None)
2019-03-03 19:20:07 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 38377, None)
2019-03-03 19:20:07 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 38377, None)
2019-03-03 19:20:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:20:07 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 33554432
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 137438955520000
Total Bytes 0
Elapsed Time 2.004253e+02 seconds
FLOP/s 6.857365e+11
B/s 0.000000e+00
2019-03-03 19:27:21 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:27:21 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:27:22 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:27:22 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:27:22 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:27:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:27:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:27:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:27:22 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 39659.
2019-03-03 19:27:22 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:27:22 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:27:22 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:27:22 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:27:22 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-759c4913-ba37-4071-8eb7-38d000df1d8b
2019-03-03 19:27:22 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:27:22 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:27:22 INFO  log:192 - Logging initialized @5612ms
2019-03-03 19:27:22 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:27:22 INFO  Server:414 - Started @5721ms
2019-03-03 19:27:23 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:27:23 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:27:23 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 19:27:23 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:39659/jars/Taskbench-assembly-1.0.jar with timestamp 1551670043187
2019-03-03 19:27:23 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:39659/files/libcore_c.so with timestamp 1551670043190
2019-03-03 19:27:23 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-76d3a17a-e7c1-4a0a-99e8-cc38e1a7f076/userFiles-53a867ba-e2df-4c59-8a46-663de4581c27/libcore_c.so
2019-03-03 19:27:23 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 19:27:23 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 61 ms (0 ms spent in bootstraps)
2019-03-03 19:27:23 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303192723-0009
2019-03-03 19:27:23 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303192723-0009/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 19:27:23 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303192723-0009/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 19:27:23 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303192723-0009/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 19:27:23 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303192723-0009/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 19:27:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33672.
2019-03-03 19:27:23 INFO  NettyBlockTransferService:54 - Server created on nid00963:33672
2019-03-03 19:27:23 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:27:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 33672, None)
2019-03-03 19:27:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:33672 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 33672, None)
2019-03-03 19:27:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 33672, None)
2019-03-03 19:27:23 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 33672, None)
2019-03-03 19:27:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:27:24 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 33554432
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 137438955520000
Total Bytes 0
Elapsed Time 1.996886e+02 seconds
FLOP/s 6.882665e+11
B/s 0.000000e+00
2019-03-03 19:34:36 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:34:36 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:34:37 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:34:37 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:34:37 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:34:37 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:34:37 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:34:37 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:34:37 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 41892.
2019-03-03 19:34:37 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:34:37 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:34:37 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:34:37 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:34:37 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-d7a01466-4654-4432-b440-2cd5ac4ae34f
2019-03-03 19:34:37 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:34:37 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:34:37 INFO  log:192 - Logging initialized @6192ms
2019-03-03 19:34:37 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:34:37 INFO  Server:414 - Started @6287ms
2019-03-03 19:34:37 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:34:37 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:34:37 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 19:34:38 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:41892/jars/Taskbench-assembly-1.0.jar with timestamp 1551670478009
2019-03-03 19:34:38 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:41892/files/libcore_c.so with timestamp 1551670478012
2019-03-03 19:34:38 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-801f1e90-8de8-4a20-b13b-d96a47b82561/userFiles-feacca77-0f94-4152-b0f0-eec75d095181/libcore_c.so
2019-03-03 19:34:38 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 19:34:38 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 47 ms (0 ms spent in bootstraps)
2019-03-03 19:34:38 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303193438-0010
2019-03-03 19:34:38 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303193438-0010/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 19:34:38 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303193438-0010/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 19:34:38 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303193438-0010/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 19:34:38 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303193438-0010/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 19:34:38 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35961.
2019-03-03 19:34:38 INFO  NettyBlockTransferService:54 - Server created on nid00963:35961
2019-03-03 19:34:38 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:34:38 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 35961, None)
2019-03-03 19:34:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:35961 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 35961, None)
2019-03-03 19:34:38 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 35961, None)
2019-03-03 19:34:38 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 35961, None)
2019-03-03 19:34:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:34:38 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 16777216
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 68719478784000
Total Bytes 0
Elapsed Time 1.036217e+02 seconds
FLOP/s 6.631762e+11
B/s 0.000000e+00
2019-03-03 19:38:37 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:38:38 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:38:38 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:38:38 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:38:38 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:38:38 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:38:38 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:38:38 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:38:38 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 44507.
2019-03-03 19:38:38 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:38:38 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:38:38 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:38:38 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:38:38 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-37491bb5-64e6-4135-81a2-4b08c111eec2
2019-03-03 19:38:39 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:38:39 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:38:39 INFO  log:192 - Logging initialized @5816ms
2019-03-03 19:38:39 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:38:39 INFO  Server:414 - Started @5921ms
2019-03-03 19:38:39 INFO  AbstractConnector:278 - Started ServerConnector@779dfe55{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:38:39 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 19:38:39 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:44507/jars/Taskbench-assembly-1.0.jar with timestamp 1551670719401
2019-03-03 19:38:39 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:44507/files/libcore_c.so with timestamp 1551670719404
2019-03-03 19:38:39 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-4cae6da1-9f1d-49d8-8bd6-5bd14bc8cabe/userFiles-5af3e33b-c4a2-49a5-950d-e8ce53d6e22a/libcore_c.so
2019-03-03 19:38:39 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 19:38:39 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 45 ms (0 ms spent in bootstraps)
2019-03-03 19:38:39 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303193839-0011
2019-03-03 19:38:39 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303193839-0011/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 19:38:39 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303193839-0011/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 19:38:39 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303193839-0011/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 19:38:39 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303193839-0011/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 19:38:39 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43130.
2019-03-03 19:38:39 INFO  NettyBlockTransferService:54 - Server created on nid00963:43130
2019-03-03 19:38:39 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:38:39 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 43130, None)
2019-03-03 19:38:39 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:43130 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 43130, None)
2019-03-03 19:38:39 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 43130, None)
2019-03-03 19:38:39 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 43130, None)
2019-03-03 19:38:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:38:39 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 16777216
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 68719478784000
Total Bytes 0
Elapsed Time 1.038937e+02 seconds
FLOP/s 6.614402e+11
B/s 0.000000e+00
2019-03-03 19:42:48 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:42:49 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:42:49 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:42:49 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:42:49 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:42:49 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:42:49 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:42:49 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:42:50 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 38191.
2019-03-03 19:42:50 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:42:50 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:42:50 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:42:50 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:42:50 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-5e797e22-e792-4e10-9270-33147113955e
2019-03-03 19:42:50 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:42:50 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:42:50 INFO  log:192 - Logging initialized @7204ms
2019-03-03 19:42:50 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:42:50 INFO  Server:414 - Started @7299ms
2019-03-03 19:42:50 INFO  AbstractConnector:278 - Started ServerConnector@5c58ac78{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:42:50 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@58faa93b{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27cbfddf{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/static,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c2772d1{/,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/api,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@381cad29{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:42:50 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 19:42:50 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:38191/jars/Taskbench-assembly-1.0.jar with timestamp 1551670970875
2019-03-03 19:42:50 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:38191/files/libcore_c.so with timestamp 1551670970878
2019-03-03 19:42:50 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-121fca75-2c49-4c07-aaa3-2a890f14af51/userFiles-24569745-8468-42bc-85c3-30ae0ac73a96/libcore_c.so
2019-03-03 19:42:51 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 19:42:51 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 49 ms (0 ms spent in bootstraps)
2019-03-03 19:42:51 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303194251-0012
2019-03-03 19:42:51 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303194251-0012/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 19:42:51 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303194251-0012/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 19:42:51 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303194251-0012/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 19:42:51 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303194251-0012/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 19:42:51 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41823.
2019-03-03 19:42:51 INFO  NettyBlockTransferService:54 - Server created on nid00963:41823
2019-03-03 19:42:51 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:42:51 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 41823, None)
2019-03-03 19:42:51 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:41823 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 41823, None)
2019-03-03 19:42:51 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 41823, None)
2019-03-03 19:42:51 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 41823, None)
2019-03-03 19:42:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f52eb6f{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:42:51 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 16777216
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 68719478784000
Total Bytes 0
Elapsed Time 1.029851e+02 seconds
FLOP/s 6.672759e+11
B/s 0.000000e+00
2019-03-03 19:47:01 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:47:01 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:47:01 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:47:01 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:47:01 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:47:01 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:47:01 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:47:01 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:47:02 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 41969.
2019-03-03 19:47:02 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:47:02 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:47:02 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:47:02 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:47:02 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-2b3f0d45-b544-4e9b-a4f4-ae20e8073db6
2019-03-03 19:47:02 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:47:02 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:47:02 INFO  log:192 - Logging initialized @4791ms
2019-03-03 19:47:02 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:47:02 INFO  Server:414 - Started @4901ms
2019-03-03 19:47:02 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:47:02 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:47:02 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 19:47:02 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:41969/jars/Taskbench-assembly-1.0.jar with timestamp 1551671222833
2019-03-03 19:47:02 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:41969/files/libcore_c.so with timestamp 1551671222836
2019-03-03 19:47:02 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-9256f783-587c-48a3-b8cc-e24e28b4e9dd/userFiles-a0a72298-e090-4776-9b1e-e36e9f120f66/libcore_c.so
2019-03-03 19:47:02 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 19:47:03 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 46 ms (0 ms spent in bootstraps)
2019-03-03 19:47:03 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303194703-0013
2019-03-03 19:47:03 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303194703-0013/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 19:47:03 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303194703-0013/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 19:47:03 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303194703-0013/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 19:47:03 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303194703-0013/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 19:47:03 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35125.
2019-03-03 19:47:03 INFO  NettyBlockTransferService:54 - Server created on nid00963:35125
2019-03-03 19:47:03 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:47:03 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 35125, None)
2019-03-03 19:47:03 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:35125 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 35125, None)
2019-03-03 19:47:03 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 35125, None)
2019-03-03 19:47:03 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 35125, None)
2019-03-03 19:47:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:47:03 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 16777216
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 68719478784000
Total Bytes 0
Elapsed Time 1.037117e+02 seconds
FLOP/s 6.626007e+11
B/s 0.000000e+00
2019-03-03 19:51:08 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:51:08 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:51:08 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:51:08 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:51:08 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:51:08 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:51:08 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:51:08 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:51:09 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 33214.
2019-03-03 19:51:09 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:51:09 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:51:09 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:51:09 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:51:09 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-ac6fd2cc-c628-476f-87c9-f4e23194a1bc
2019-03-03 19:51:09 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:51:09 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:51:09 INFO  log:192 - Logging initialized @4921ms
2019-03-03 19:51:09 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:51:09 INFO  Server:414 - Started @5016ms
2019-03-03 19:51:09 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:51:09 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:51:09 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 19:51:09 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:33214/jars/Taskbench-assembly-1.0.jar with timestamp 1551671469830
2019-03-03 19:51:09 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:33214/files/libcore_c.so with timestamp 1551671469833
2019-03-03 19:51:09 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-c01bf939-e9ad-45c8-bf0f-30bb549c7849/userFiles-f8bf6e63-b7fb-4359-8844-a818bbb81eba/libcore_c.so
2019-03-03 19:51:09 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 19:51:10 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 46 ms (0 ms spent in bootstraps)
2019-03-03 19:51:10 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303195110-0014
2019-03-03 19:51:10 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303195110-0014/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 19:51:10 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303195110-0014/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 19:51:10 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303195110-0014/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 19:51:10 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303195110-0014/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 19:51:10 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37281.
2019-03-03 19:51:10 INFO  NettyBlockTransferService:54 - Server created on nid00963:37281
2019-03-03 19:51:10 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:51:10 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 37281, None)
2019-03-03 19:51:10 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:37281 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 37281, None)
2019-03-03 19:51:10 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 37281, None)
2019-03-03 19:51:10 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 37281, None)
2019-03-03 19:51:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:51:10 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 16777216
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 68719478784000
Total Bytes 0
Elapsed Time 1.032365e+02 seconds
FLOP/s 6.656512e+11
B/s 0.000000e+00
2019-03-03 19:55:26 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:55:26 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:55:26 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:55:26 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:55:26 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:55:26 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:55:26 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:55:26 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:55:27 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40731.
2019-03-03 19:55:27 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:55:27 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:55:27 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:55:27 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:55:27 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-633bb2cd-de04-49a1-b158-fda0eef7ad0d
2019-03-03 19:55:27 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:55:27 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:55:27 INFO  log:192 - Logging initialized @5373ms
2019-03-03 19:55:27 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:55:27 INFO  Server:414 - Started @5476ms
2019-03-03 19:55:27 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:55:27 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:55:27 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 19:55:27 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:40731/jars/Taskbench-assembly-1.0.jar with timestamp 1551671727607
2019-03-03 19:55:27 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:40731/files/libcore_c.so with timestamp 1551671727610
2019-03-03 19:55:27 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-73fcfd83-d62d-451d-be57-fff32d3600e4/userFiles-38aa9192-942d-4691-9b02-bbd9084d8b7f/libcore_c.so
2019-03-03 19:55:27 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 19:55:27 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 49 ms (0 ms spent in bootstraps)
2019-03-03 19:55:27 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303195527-0015
2019-03-03 19:55:27 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303195527-0015/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 19:55:27 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303195527-0015/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 19:55:27 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303195527-0015/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 19:55:27 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303195527-0015/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 19:55:27 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38838.
2019-03-03 19:55:27 INFO  NettyBlockTransferService:54 - Server created on nid00963:38838
2019-03-03 19:55:27 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:55:27 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 38838, None)
2019-03-03 19:55:27 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:38838 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 38838, None)
2019-03-03 19:55:27 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 38838, None)
2019-03-03 19:55:27 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 38838, None)
2019-03-03 19:55:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:55:28 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 8388608
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 34359740416000
Total Bytes 0
Elapsed Time 5.558258e+01 seconds
FLOP/s 6.181746e+11
B/s 0.000000e+00
2019-03-03 19:57:56 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 19:57:57 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 19:57:57 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 19:57:57 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 19:57:57 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 19:57:57 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 19:57:57 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 19:57:57 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 19:57:57 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 45981.
2019-03-03 19:57:57 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 19:57:57 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 19:57:57 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 19:57:57 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 19:57:57 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-04a7d3a6-45f8-49db-814f-e8beda8822d7
2019-03-03 19:57:57 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 19:57:57 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 19:57:58 INFO  log:192 - Logging initialized @4575ms
2019-03-03 19:57:58 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 19:57:58 INFO  Server:414 - Started @4670ms
2019-03-03 19:57:58 INFO  AbstractConnector:278 - Started ServerConnector@19ba3f7a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 19:57:58 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@127d7908{/jobs,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/static,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/api,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 19:57:58 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:45981/jars/Taskbench-assembly-1.0.jar with timestamp 1551671878289
2019-03-03 19:57:58 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:45981/files/libcore_c.so with timestamp 1551671878292
2019-03-03 19:57:58 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-3f74f0ca-0fd2-4136-96fc-cf4f8d4498cf/userFiles-72c0a387-d90c-49ff-958b-79d61204929e/libcore_c.so
2019-03-03 19:57:58 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 19:57:58 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 51 ms (0 ms spent in bootstraps)
2019-03-03 19:57:58 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303195758-0016
2019-03-03 19:57:58 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303195758-0016/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 19:57:58 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303195758-0016/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 19:57:58 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303195758-0016/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 19:57:58 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303195758-0016/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 19:57:58 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34032.
2019-03-03 19:57:58 INFO  NettyBlockTransferService:54 - Server created on nid00963:34032
2019-03-03 19:57:58 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 19:57:58 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 34032, None)
2019-03-03 19:57:58 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:34032 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 34032, None)
2019-03-03 19:57:58 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 34032, None)
2019-03-03 19:57:58 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 34032, None)
2019-03-03 19:57:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@58294867{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 19:57:58 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 8388608
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 34359740416000
Total Bytes 0
Elapsed Time 5.524912e+01 seconds
FLOP/s 6.219057e+11
B/s 0.000000e+00
2019-03-03 20:00:21 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:00:21 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:00:22 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:00:22 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:00:22 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:00:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:00:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:00:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:00:22 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 45546.
2019-03-03 20:00:22 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:00:22 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:00:22 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:00:22 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:00:22 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-e9377792-3007-4a51-9330-9eef66cd666c
2019-03-03 20:00:22 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:00:22 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:00:22 INFO  log:192 - Logging initialized @6025ms
2019-03-03 20:00:22 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:00:22 INFO  Server:414 - Started @6121ms
2019-03-03 20:00:22 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:00:22 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 20:00:23 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:45546/jars/Taskbench-assembly-1.0.jar with timestamp 1551672023114
2019-03-03 20:00:23 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:45546/files/libcore_c.so with timestamp 1551672023117
2019-03-03 20:00:23 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-3f1218a4-eae1-4493-8126-4ac23923f70b/userFiles-db0270ae-123e-4414-b6c2-ba547a58fc91/libcore_c.so
2019-03-03 20:00:23 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 20:00:23 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 44 ms (0 ms spent in bootstraps)
2019-03-03 20:00:23 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303200023-0017
2019-03-03 20:00:23 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303200023-0017/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 20:00:23 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303200023-0017/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 20:00:23 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303200023-0017/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 20:00:23 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303200023-0017/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 20:00:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46622.
2019-03-03 20:00:23 INFO  NettyBlockTransferService:54 - Server created on nid00963:46622
2019-03-03 20:00:23 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:00:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 46622, None)
2019-03-03 20:00:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:46622 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 46622, None)
2019-03-03 20:00:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 46622, None)
2019-03-03 20:00:23 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 46622, None)
2019-03-03 20:00:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:00:23 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 8388608
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 34359740416000
Total Bytes 0
Elapsed Time 5.585276e+01 seconds
FLOP/s 6.151842e+11
B/s 0.000000e+00
2019-03-03 20:02:45 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:02:45 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:02:46 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:02:46 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:02:46 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:02:46 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:02:46 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:02:46 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:02:46 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 43574.
2019-03-03 20:02:46 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:02:46 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:02:46 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:02:46 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:02:46 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-e27bd197-d671-4ca1-9e5d-e05924fcc194
2019-03-03 20:02:46 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:02:46 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:02:46 INFO  log:192 - Logging initialized @5454ms
2019-03-03 20:02:46 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:02:46 INFO  Server:414 - Started @5564ms
2019-03-03 20:02:46 INFO  AbstractConnector:278 - Started ServerConnector@779dfe55{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:02:46 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f212d84{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/static,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d00a23{/,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433e536f{/api,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@988246e{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62515a47{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:02:46 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 20:02:47 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:43574/jars/Taskbench-assembly-1.0.jar with timestamp 1551672167065
2019-03-03 20:02:47 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:43574/files/libcore_c.so with timestamp 1551672167069
2019-03-03 20:02:47 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-d37baa95-fb5f-445a-b31a-ad8ea62ef9f0/userFiles-aa01ff6b-fbf1-411c-aa1e-73502fa9f0d3/libcore_c.so
2019-03-03 20:02:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 20:02:47 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 52 ms (0 ms spent in bootstraps)
2019-03-03 20:02:47 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303200247-0018
2019-03-03 20:02:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303200247-0018/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 20:02:47 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303200247-0018/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 20:02:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303200247-0018/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 20:02:47 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303200247-0018/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 20:02:47 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34591.
2019-03-03 20:02:47 INFO  NettyBlockTransferService:54 - Server created on nid00963:34591
2019-03-03 20:02:47 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:02:47 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 34591, None)
2019-03-03 20:02:47 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:34591 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 34591, None)
2019-03-03 20:02:47 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 34591, None)
2019-03-03 20:02:47 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 34591, None)
2019-03-03 20:02:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57d0fc89{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:02:47 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 8388608
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 34359740416000
Total Bytes 0
Elapsed Time 5.877398e+01 seconds
FLOP/s 5.846081e+11
B/s 0.000000e+00
2019-03-03 20:05:42 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:05:42 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:05:42 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:05:42 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:05:42 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:05:42 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:05:42 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:05:42 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:05:43 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 43749.
2019-03-03 20:05:43 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:05:43 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:05:43 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:05:43 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:05:43 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-1a808e01-7b47-472f-8d3e-917f16d1d6e0
2019-03-03 20:05:43 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:05:43 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:05:43 INFO  log:192 - Logging initialized @5176ms
2019-03-03 20:05:43 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:05:43 INFO  Server:414 - Started @5276ms
2019-03-03 20:05:43 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:05:43 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:05:43 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 20:05:43 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:43749/jars/Taskbench-assembly-1.0.jar with timestamp 1551672343534
2019-03-03 20:05:43 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:43749/files/libcore_c.so with timestamp 1551672343536
2019-03-03 20:05:43 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-00f0630d-caaa-40d1-adbc-cfb2d1b3b16e/userFiles-12b180e5-0534-4de2-b0c4-85c55cc583ef/libcore_c.so
2019-03-03 20:05:43 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 20:05:43 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 50 ms (0 ms spent in bootstraps)
2019-03-03 20:05:43 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303200543-0019
2019-03-03 20:05:43 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303200543-0019/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 20:05:43 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303200543-0019/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 20:05:43 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303200543-0019/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 20:05:43 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303200543-0019/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 20:05:43 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35071.
2019-03-03 20:05:43 INFO  NettyBlockTransferService:54 - Server created on nid00963:35071
2019-03-03 20:05:43 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:05:43 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 35071, None)
2019-03-03 20:05:43 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:35071 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 35071, None)
2019-03-03 20:05:43 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 35071, None)
2019-03-03 20:05:43 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 35071, None)
2019-03-03 20:05:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:05:44 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 8388608
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 34359740416000
Total Bytes 0
Elapsed Time 5.608747e+01 seconds
FLOP/s 6.126099e+11
B/s 0.000000e+00
2019-03-03 20:08:10 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:08:10 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:08:10 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:08:10 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:08:10 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:08:10 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:08:10 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:08:10 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:08:11 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 44670.
2019-03-03 20:08:11 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:08:11 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:08:11 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:08:11 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:08:11 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-16b69bef-e6c6-407f-a1a4-62296e38941a
2019-03-03 20:08:11 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:08:11 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:08:11 INFO  log:192 - Logging initialized @4523ms
2019-03-03 20:08:11 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:08:11 INFO  Server:414 - Started @4625ms
2019-03-03 20:08:11 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:08:11 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:08:11 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 20:08:11 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:44670/jars/Taskbench-assembly-1.0.jar with timestamp 1551672491555
2019-03-03 20:08:11 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:44670/files/libcore_c.so with timestamp 1551672491558
2019-03-03 20:08:11 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-c7e059ed-48e9-4134-8678-090897307cb5/userFiles-dba08a15-7fc3-4ec4-ac06-8dd8433649b9/libcore_c.so
2019-03-03 20:08:11 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 20:08:11 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 47 ms (0 ms spent in bootstraps)
2019-03-03 20:08:11 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303200811-0020
2019-03-03 20:08:11 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303200811-0020/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 20:08:11 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303200811-0020/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 20:08:11 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303200811-0020/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 20:08:11 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303200811-0020/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 20:08:11 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43088.
2019-03-03 20:08:11 INFO  NettyBlockTransferService:54 - Server created on nid00963:43088
2019-03-03 20:08:11 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:08:11 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 43088, None)
2019-03-03 20:08:11 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:43088 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 43088, None)
2019-03-03 20:08:11 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 43088, None)
2019-03-03 20:08:11 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 43088, None)
2019-03-03 20:08:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:08:12 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 4194304
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 17179871232000
Total Bytes 0
Elapsed Time 3.165797e+01 seconds
FLOP/s 5.426713e+11
B/s 0.000000e+00
2019-03-03 20:09:45 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:09:46 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:09:46 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:09:46 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:09:46 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:09:46 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:09:46 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:09:46 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:09:46 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 42638.
2019-03-03 20:09:46 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:09:46 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:09:46 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:09:46 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:09:46 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-168ca74c-f067-433d-9646-462583300530
2019-03-03 20:09:46 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:09:46 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:09:46 INFO  log:192 - Logging initialized @4211ms
2019-03-03 20:09:47 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:09:47 INFO  Server:414 - Started @4314ms
2019-03-03 20:09:47 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:09:47 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 20:09:47 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:42638/jars/Taskbench-assembly-1.0.jar with timestamp 1551672587259
2019-03-03 20:09:47 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:42638/files/libcore_c.so with timestamp 1551672587262
2019-03-03 20:09:47 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-044517fd-ea9f-4d85-9a87-b1720fc89622/userFiles-56d90aab-5145-4336-8fdd-caa43d29310a/libcore_c.so
2019-03-03 20:09:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 20:09:47 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 47 ms (0 ms spent in bootstraps)
2019-03-03 20:09:47 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303200947-0021
2019-03-03 20:09:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303200947-0021/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 20:09:47 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303200947-0021/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 20:09:47 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303200947-0021/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 20:09:47 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303200947-0021/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 20:09:47 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38189.
2019-03-03 20:09:47 INFO  NettyBlockTransferService:54 - Server created on nid00963:38189
2019-03-03 20:09:47 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:09:47 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 38189, None)
2019-03-03 20:09:47 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:38189 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 38189, None)
2019-03-03 20:09:47 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 38189, None)
2019-03-03 20:09:47 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 38189, None)
2019-03-03 20:09:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:09:47 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 4194304
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 17179871232000
Total Bytes 0
Elapsed Time 3.203529e+01 seconds
FLOP/s 5.362796e+11
B/s 0.000000e+00
2019-03-03 20:11:27 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:11:27 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:11:27 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:11:27 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:11:27 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:11:27 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:11:27 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:11:27 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:11:28 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40796.
2019-03-03 20:11:28 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:11:28 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:11:28 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:11:28 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:11:28 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-d86194d8-bf83-4ea3-9e21-2cee7ba06e75
2019-03-03 20:11:28 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:11:28 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:11:28 INFO  log:192 - Logging initialized @5250ms
2019-03-03 20:11:28 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:11:28 INFO  Server:414 - Started @5346ms
2019-03-03 20:11:28 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:11:28 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:11:28 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 20:11:28 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:40796/jars/Taskbench-assembly-1.0.jar with timestamp 1551672688733
2019-03-03 20:11:28 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:40796/files/libcore_c.so with timestamp 1551672688737
2019-03-03 20:11:28 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-40179d4c-3920-44fc-927f-4ca0ad8b18ec/userFiles-a7df861d-f329-4c63-94c1-33aa9a723a98/libcore_c.so
2019-03-03 20:11:28 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 20:11:28 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 48 ms (0 ms spent in bootstraps)
2019-03-03 20:11:29 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303201129-0022
2019-03-03 20:11:29 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201129-0022/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 20:11:29 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201129-0022/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 20:11:29 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201129-0022/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 20:11:29 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201129-0022/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 20:11:29 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40725.
2019-03-03 20:11:29 INFO  NettyBlockTransferService:54 - Server created on nid00963:40725
2019-03-03 20:11:29 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:11:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 40725, None)
2019-03-03 20:11:29 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:40725 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 40725, None)
2019-03-03 20:11:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 40725, None)
2019-03-03 20:11:29 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 40725, None)
2019-03-03 20:11:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:11:29 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 4194304
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 17179871232000
Total Bytes 0
Elapsed Time 4.704635e+01 seconds
FLOP/s 3.651690e+11
B/s 0.000000e+00
2019-03-03 20:13:36 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:13:37 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:13:37 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:13:37 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:13:37 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:13:37 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:13:37 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:13:37 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:13:38 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 46089.
2019-03-03 20:13:38 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:13:38 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:13:38 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:13:38 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:13:38 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-2bf230c2-34ac-4338-bc17-adb53ae11e74
2019-03-03 20:13:38 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:13:38 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:13:38 INFO  log:192 - Logging initialized @8018ms
2019-03-03 20:13:38 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:13:38 INFO  Server:414 - Started @8216ms
2019-03-03 20:13:38 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:13:38 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:13:38 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 20:13:38 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:46089/jars/Taskbench-assembly-1.0.jar with timestamp 1551672818809
2019-03-03 20:13:38 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:46089/files/libcore_c.so with timestamp 1551672818812
2019-03-03 20:13:38 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-f85e6499-088e-4265-b1fc-a30938b4bc1a/userFiles-b4ef09d4-69db-467a-8a48-b43c2256ffeb/libcore_c.so
2019-03-03 20:13:39 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 20:13:39 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 68 ms (0 ms spent in bootstraps)
2019-03-03 20:13:39 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303201339-0023
2019-03-03 20:13:39 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201339-0023/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 20:13:39 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201339-0023/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 20:13:39 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201339-0023/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 20:13:39 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201339-0023/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 20:13:39 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37755.
2019-03-03 20:13:39 INFO  NettyBlockTransferService:54 - Server created on nid00963:37755
2019-03-03 20:13:39 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:13:39 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 37755, None)
2019-03-03 20:13:39 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:37755 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 37755, None)
2019-03-03 20:13:39 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 37755, None)
2019-03-03 20:13:39 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 37755, None)
2019-03-03 20:13:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:13:39 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 4194304
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 17179871232000
Total Bytes 0
Elapsed Time 3.295099e+01 seconds
FLOP/s 5.213765e+11
B/s 0.000000e+00
2019-03-03 20:15:18 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:15:18 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:15:18 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:15:18 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:15:18 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:15:18 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:15:18 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:15:18 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:15:19 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 38430.
2019-03-03 20:15:19 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:15:19 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:15:19 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:15:19 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:15:19 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-c76e9878-bbd7-40c8-9e79-976a71f11576
2019-03-03 20:15:19 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:15:19 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:15:19 INFO  log:192 - Logging initialized @4359ms
2019-03-03 20:15:19 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:15:19 INFO  Server:414 - Started @4455ms
2019-03-03 20:15:19 INFO  AbstractConnector:278 - Started ServerConnector@5849ffea{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:15:19 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:15:19 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 20:15:19 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:38430/jars/Taskbench-assembly-1.0.jar with timestamp 1551672919816
2019-03-03 20:15:19 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:38430/files/libcore_c.so with timestamp 1551672919818
2019-03-03 20:15:19 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-1d09c48f-e994-4487-adff-8ac2cde74cde/userFiles-686d8418-51b2-4e3a-ac2f-f68e3a495de0/libcore_c.so
2019-03-03 20:15:19 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 20:15:20 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 46 ms (0 ms spent in bootstraps)
2019-03-03 20:15:20 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303201520-0024
2019-03-03 20:15:20 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201520-0024/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 20:15:20 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201520-0024/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 20:15:20 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201520-0024/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 20:15:20 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201520-0024/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 20:15:20 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40187.
2019-03-03 20:15:20 INFO  NettyBlockTransferService:54 - Server created on nid00963:40187
2019-03-03 20:15:20 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:15:20 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 40187, None)
2019-03-03 20:15:20 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:40187 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 40187, None)
2019-03-03 20:15:20 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 40187, None)
2019-03-03 20:15:20 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 40187, None)
2019-03-03 20:15:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:15:20 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 4194304
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 17179871232000
Total Bytes 0
Elapsed Time 3.271549e+01 seconds
FLOP/s 5.251295e+11
B/s 0.000000e+00
2019-03-03 20:16:55 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:16:55 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:16:55 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:16:55 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:16:55 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:16:55 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:16:55 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:16:55 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:16:56 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40800.
2019-03-03 20:16:56 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:16:56 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:16:56 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:16:56 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:16:56 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-94687602-f09d-4d09-8595-53ebb179450b
2019-03-03 20:16:56 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:16:56 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:16:56 INFO  log:192 - Logging initialized @5530ms
2019-03-03 20:16:56 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:16:56 INFO  Server:414 - Started @5629ms
2019-03-03 20:16:56 INFO  AbstractConnector:278 - Started ServerConnector@1699f592{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:16:56 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:16:56 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 20:16:56 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:40800/jars/Taskbench-assembly-1.0.jar with timestamp 1551673016820
2019-03-03 20:16:56 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:40800/files/libcore_c.so with timestamp 1551673016823
2019-03-03 20:16:56 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-5b664b17-3592-4985-b165-6bb871a3cbb0/userFiles-5e7fed19-fdbc-423e-b4ef-490d77fcc963/libcore_c.so
2019-03-03 20:16:56 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 20:16:57 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 49 ms (0 ms spent in bootstraps)
2019-03-03 20:16:57 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303201657-0025
2019-03-03 20:16:57 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201657-0025/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 20:16:57 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201657-0025/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 20:16:57 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201657-0025/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 20:16:57 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201657-0025/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 20:16:57 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39261.
2019-03-03 20:16:57 INFO  NettyBlockTransferService:54 - Server created on nid00963:39261
2019-03-03 20:16:57 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:16:57 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 39261, None)
2019-03-03 20:16:57 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:39261 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 39261, None)
2019-03-03 20:16:57 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 39261, None)
2019-03-03 20:16:57 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 39261, None)
2019-03-03 20:16:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:16:57 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
Starting timing
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 2097152
      Output Bytes: 16
      Scratch Bytes: 0
Total Tasks 32000
Total Dependencies 32000
Total FLOPs 8589936640000
Total Bytes 0
Elapsed Time 2.226311e+01 seconds
FLOP/s 3.858373e+11
B/s 0.000000e+00
2019-03-03 20:18:20 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:18:20 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:18:20 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:18:20 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:18:20 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:18:20 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:18:20 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:18:20 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:18:21 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 37602.
2019-03-03 20:18:21 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:18:21 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:18:21 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:18:21 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:18:21 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-79715ddf-11c0-43ca-9144-95c915946491
2019-03-03 20:18:21 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:18:21 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:18:21 INFO  log:192 - Logging initialized @6463ms
2019-03-03 20:18:21 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:18:21 INFO  Server:414 - Started @6568ms
2019-03-03 20:18:21 INFO  AbstractConnector:278 - Started ServerConnector@1144a55a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:18:21 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:18:21 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 20:18:21 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:37602/jars/Taskbench-assembly-1.0.jar with timestamp 1551673101735
2019-03-03 20:18:21 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:37602/files/libcore_c.so with timestamp 1551673101738
2019-03-03 20:18:21 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-b706247f-1283-4e90-8d33-f868b2221090/userFiles-acb115bd-1b71-41ce-b404-1938744d3d31/libcore_c.so
2019-03-03 20:18:21 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 20:18:22 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 53 ms (0 ms spent in bootstraps)
2019-03-03 20:18:22 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303201822-0026
2019-03-03 20:18:22 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201822-0026/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 20:18:22 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201822-0026/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 20:18:22 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201822-0026/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 20:18:22 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201822-0026/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 20:18:22 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44699.
2019-03-03 20:18:22 INFO  NettyBlockTransferService:54 - Server created on nid00963:44699
2019-03-03 20:18:22 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:18:22 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 44699, None)
2019-03-03 20:18:22 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:44699 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 44699, None)
2019-03-03 20:18:22 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 44699, None)
2019-03-03 20:18:22 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 44699, None)
2019-03-03 20:18:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:18:22 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
2019-03-03 20:19:04 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job
Running Task Benchmark
  Configuration:
    Task Graph 1:
      Time Steps: 1000
      Max Width: 32
      Dependence Type: no_comm
      Radix: 5
      Period: 0
      Fraction Connected: 0.250000
      Kernel:
        Type: compute_bound
        Iterations: 2097152
      Output Bytes: 16
      Scratch Bytes: 0
2019-03-03 20:19:14 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-03 20:19:15 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-03-03 20:19:15 INFO  SparkContext:54 - Submitted application: SimpleApplication
2019-03-03 20:19:15 INFO  SecurityManager:54 - Changing view acls to: slaughte
2019-03-03 20:19:15 INFO  SecurityManager:54 - Changing modify acls to: slaughte
2019-03-03 20:19:15 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-03 20:19:15 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-03 20:19:15 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(slaughte); groups with view permissions: Set(); users  with modify permissions: Set(slaughte); groups with modify permissions: Set()
2019-03-03 20:19:15 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35448.
2019-03-03 20:19:15 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-03 20:19:15 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-03 20:19:15 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-03 20:19:15 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-03 20:19:15 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark/blockmgr-536a3cf8-fe13-4131-9412-f8eb21bcdda1
2019-03-03 20:19:15 INFO  MemoryStore:54 - MemoryStore started with capacity 34.0 GB
2019-03-03 20:19:15 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-03 20:19:16 INFO  log:192 - Logging initialized @8695ms
2019-03-03 20:19:16 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-03-03 20:19:16 INFO  Server:414 - Started @8796ms
2019-03-03 20:19:16 INFO  AbstractConnector:278 - Started ServerConnector@8e71c2a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-03 20:19:16 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9c69a9{/jobs,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/jobs/json,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/jobs/job,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/stages,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/stages/json,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/stages/stage,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/stages/pool,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56febdc{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/storage,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/storage/json,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@294bdeb4{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5300f14a{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f86099a{/environment,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/environment/json,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/executors,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54acff7d{/executors/json,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bc9e6ab{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5488b5c5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4248ed58{/static,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@89c65d5{/,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@faa3fed{/api,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f2c3f0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://nid00963:4040
2019-03-03 20:19:16 INFO  SparkContext:54 - Added JAR file:/global/homes/s/slaughte/task-bench/experiments/cori_metg_compute/../../spark/target/scala-2.11/Taskbench-assembly-1.0.jar at spark://nid00963:35448/jars/Taskbench-assembly-1.0.jar with timestamp 1551673156336
2019-03-03 20:19:16 INFO  SparkContext:54 - Added file file:///global/homes/s/slaughte/task-bench/spark/libcore_c.so at spark://nid00963:35448/files/libcore_c.so with timestamp 1551673156340
2019-03-03 20:19:16 INFO  Utils:54 - Copying /global/homes/s/slaughte/task-bench/spark/libcore_c.so to /tmp/spark/spark-fcb394ca-7c9b-4898-8062-5b3458202ecd/userFiles-2fd773f2-4f96-42c6-b5ae-59d657da4c01/libcore_c.so
2019-03-03 20:19:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://nid00963:7077...
2019-03-03 20:19:16 INFO  TransportClientFactory:267 - Successfully created connection to nid00963/10.128.3.202:7077 after 50 ms (0 ms spent in bootstraps)
2019-03-03 20:19:16 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190303201916-0027
2019-03-03 20:19:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201916-0027/0 on worker-20190303164035-10.128.4.157-38997 (10.128.4.157:38997) with 16 core(s)
2019-03-03 20:19:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201916-0027/0 on hostPort 10.128.4.157:38997 with 16 core(s), 64.0 GB RAM
2019-03-03 20:19:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190303201916-0027/1 on worker-20190303164035-10.128.4.157-46044 (10.128.4.157:46044) with 16 core(s)
2019-03-03 20:19:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190303201916-0027/1 on hostPort 10.128.4.157:46044 with 16 core(s), 64.0 GB RAM
2019-03-03 20:19:16 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34342.
2019-03-03 20:19:16 INFO  NettyBlockTransferService:54 - Server created on nid00963:34342
2019-03-03 20:19:16 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-03 20:19:16 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, nid00963, 34342, None)
2019-03-03 20:19:16 INFO  BlockManagerMasterEndpoint:54 - Registering block manager nid00963:34342 with 34.0 GB RAM, BlockManagerId(driver, nid00963, 34342, None)
2019-03-03 20:19:16 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, nid00963, 34342, None)
2019-03-03 20:19:16 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, nid00963, 34342, None)
2019-03-03 20:19:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c277a0{/metrics/json,null,AVAILABLE,@Spark}
2019-03-03 20:19:16 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Num partitions: 30
Starting preprocessing
Starting warmup
2019-03-03 20:19:59 ERROR TaskSchedulerImpl:70 - Lost executor 12 on 10.128.4.157: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
